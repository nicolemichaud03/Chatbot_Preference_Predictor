{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Competition Notebook:\"LMSYS - Chatbot Arena Human Preference Predictions\"","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am conducting data exploration, analysis, and modeling in order to generate predictions for which Chatbot model will be preferred for a given prompt.","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Exploration","metadata":{}},{"cell_type":"markdown","source":"First, import necessary packages, and connect to kaggle to import competition dataset:","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T16:27:21.449984Z","iopub.execute_input":"2024-08-05T16:27:21.450350Z","iopub.status.idle":"2024-08-05T16:27:21.932827Z","shell.execute_reply.started":"2024-08-05T16:27:21.450309Z","shell.execute_reply":"2024-08-05T16:27:21.931833Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n/kaggle/input/lmsys-chatbot-arena/train.csv\n/kaggle/input/lmsys-chatbot-arena/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set(font_scale=2)\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.metrics import log_loss\nfrom keras.models import Model\nfrom nltk.stem import PorterStemmer, SnowballStemmer\n\n\nimport keras\nimport tensorflow as tf\nfrom keras.utils import normalize, to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, TextVectorization, Softmax, LayerNormalization, Masking, GlobalAveragePooling1D\nfrom keras.models import Sequential\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.preprocessing import sequence\nimport keras_tuner as kt\n\n# to avoid warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:21.934320Z","iopub.execute_input":"2024-08-05T16:27:21.934823Z","iopub.status.idle":"2024-08-05T16:27:28.587891Z","shell.execute_reply.started":"2024-08-05T16:27:21.934790Z","shell.execute_reply":"2024-08-05T16:27:28.587079Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"2024-08-05 16:27:24.340638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 16:27:24.340692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 16:27:24.345612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:28.589677Z","iopub.execute_input":"2024-08-05T16:27:28.591030Z","iopub.status.idle":"2024-08-05T16:27:28.595189Z","shell.execute_reply.started":"2024-08-05T16:27:28.591002Z","shell.execute_reply":"2024-08-05T16:27:28.594305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Loading and exploring the train and test datasets:","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:28.596747Z","iopub.execute_input":"2024-08-05T16:27:28.596994Z","iopub.status.idle":"2024-08-05T16:27:32.972936Z","shell.execute_reply.started":"2024-08-05T16:27:28.596973Z","shell.execute_reply":"2024-08-05T16:27:32.972005Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:32.974053Z","iopub.execute_input":"2024-08-05T16:27:32.974368Z","iopub.status.idle":"2024-08-05T16:27:32.992246Z","shell.execute_reply.started":"2024-08-05T16:27:32.974341Z","shell.execute_reply":"2024-08-05T16:27:32.991219Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:32.993538Z","iopub.execute_input":"2024-08-05T16:27:32.994281Z","iopub.status.idle":"2024-08-05T16:27:33.003302Z","shell.execute_reply.started":"2024-08-05T16:27:32.994249Z","shell.execute_reply":"2024-08-05T16:27:33.002375Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.004451Z","iopub.execute_input":"2024-08-05T16:27:33.004777Z","iopub.status.idle":"2024-08-05T16:27:33.048830Z","shell.execute_reply.started":"2024-08-05T16:27:33.004747Z","shell.execute_reply":"2024-08-05T16:27:33.047791Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.051993Z","iopub.execute_input":"2024-08-05T16:27:33.052236Z","iopub.status.idle":"2024-08-05T16:27:33.077942Z","shell.execute_reply.started":"2024-08-05T16:27:33.052215Z","shell.execute_reply":"2024-08-05T16:27:33.077135Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"I'm interested to see what models are winning most often in the datasets:","metadata":{}},{"cell_type":"code","source":"winner_a = train[train['winner_model_a']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.079061Z","iopub.execute_input":"2024-08-05T16:27:33.079730Z","iopub.status.idle":"2024-08-05T16:27:33.089012Z","shell.execute_reply.started":"2024-08-05T16:27:33.079695Z","shell.execute_reply":"2024-08-05T16:27:33.088182Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"winner_b = train[train['winner_model_b']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.090157Z","iopub.execute_input":"2024-08-05T16:27:33.090577Z","iopub.status.idle":"2024-08-05T16:27:33.098119Z","shell.execute_reply.started":"2024-08-05T16:27:33.090551Z","shell.execute_reply":"2024-08-05T16:27:33.097343Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"winner_a['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.099141Z","iopub.execute_input":"2024-08-05T16:27:33.099425Z","iopub.status.idle":"2024-08-05T16:27:33.111951Z","shell.execute_reply.started":"2024-08-05T16:27:33.099401Z","shell.execute_reply":"2024-08-05T16:27:33.111021Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"model_a\ngpt-4-1106-preview          2019\ngpt-4-0613                  1280\ngpt-3.5-turbo-0613          1213\ngpt-4-0314                  1033\nclaude-2.1                   896\n                            ... \nchatglm2-6b                   35\nqwen1.5-7b-chat               29\nopenchat-3.5-0106             28\nqwen1.5-4b-chat               19\nmistral-7b-instruct-v0.2      15\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"winner_b['model_b'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.113106Z","iopub.execute_input":"2024-08-05T16:27:33.113404Z","iopub.status.idle":"2024-08-05T16:27:33.126646Z","shell.execute_reply.started":"2024-08-05T16:27:33.113381Z","shell.execute_reply":"2024-08-05T16:27:33.125713Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"model_b\ngpt-4-1106-preview          2054\ngpt-4-0613                  1170\ngpt-3.5-turbo-0613          1168\ngpt-4-0314                   960\nclaude-1                     880\n                            ... \nchatglm2-6b                   38\nopenchat-3.5-0106             35\nqwen1.5-7b-chat               22\nqwen1.5-4b-chat               16\nmistral-7b-instruct-v0.2      12\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The top 4 models that won most often as model a or as model b are:\n- gpt-4-1106-preview\n- gpt-4-0613\n- gpt-3.5-turbo-0613\n- gpt-4-0314","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Since the 'prompt', 'response_a', and 'response_b' features are text, they need to be cleaned and pre-processed before they are tokenized and vectorized.","metadata":{}},{"cell_type":"code","source":"test_ids = test['id']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.127618Z","iopub.execute_input":"2024-08-05T16:27:33.127919Z","iopub.status.idle":"2024-08-05T16:27:33.136096Z","shell.execute_reply.started":"2024-08-05T16:27:33.127895Z","shell.execute_reply":"2024-08-05T16:27:33.135143Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Need to make sure the text features are all in string format\n\ntrain['prompt'] = train['prompt'].astype(str)\ntrain['response_a'] = train['response_a'].astype(str)\ntrain['response_b'] = train['response_b'].astype(str)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.137194Z","iopub.execute_input":"2024-08-05T16:27:33.137525Z","iopub.status.idle":"2024-08-05T16:27:33.155465Z","shell.execute_reply.started":"2024-08-05T16:27:33.137490Z","shell.execute_reply":"2024-08-05T16:27:33.154605Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Same for test data text features\ntest['prompt'] = test['prompt'].astype(str)\ntest['response_a'] = test['response_a'].astype(str)\ntest['response_b'] = test['response_b'].astype(str)\n     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the total vocab length before text cleaning/preprocessing\ncombined_text1 = train['prompt'] + ' ' + train['response_a'] + ' ' + train['response_b']\ndata1 = combined_text1.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.156527Z","iopub.execute_input":"2024-08-05T16:27:33.156800Z","iopub.status.idle":"2024-08-05T16:27:33.161822Z","shell.execute_reply.started":"2024-08-05T16:27:33.156777Z","shell.execute_reply":"2024-08-05T16:27:33.160952Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"total_vocabulary1 = set(word for combined_text1 in data1 for word in combined_text1)\nprint(len(total_vocabulary1))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.163047Z","iopub.execute_input":"2024-08-05T16:27:33.163370Z","iopub.status.idle":"2024-08-05T16:27:33.172532Z","shell.execute_reply.started":"2024-08-05T16:27:33.163346Z","shell.execute_reply":"2024-08-05T16:27:33.171706Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print('There are {} unique words in the dataset.'.format(len(total_vocabulary1)))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.173465Z","iopub.execute_input":"2024-08-05T16:27:33.173764Z","iopub.status.idle":"2024-08-05T16:27:33.182577Z","shell.execute_reply.started":"2024-08-05T16:27:33.173741Z","shell.execute_reply":"2024-08-05T16:27:33.181769Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Before cleaning and preprocessing the text features, the dataset contains 942,074 unique words.","metadata":{}},{"cell_type":"code","source":"# Creating a function to perform cleaning steps at once (Removes numbers and unnecessary characters, makes all letters lowercase, removes stopwords)\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\nno_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\nno_nums = re.compile('[\\d-]')\n\ndef clean_text(text):\n    text = no_nums.sub('', text)\n    text = no_bad_chars.sub(' ', text)\n    text = text.lower()\n    text = stemmer.stem(text)\n    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n\n    return text\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.183471Z","iopub.execute_input":"2024-08-05T16:27:33.183726Z","iopub.status.idle":"2024-08-05T16:27:33.201341Z","shell.execute_reply.started":"2024-08-05T16:27:33.183704Z","shell.execute_reply":"2024-08-05T16:27:33.200519Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#Applying text cleaning function to text columns\ntrain_cleaned = train.copy()\ntrain_cleaned['prompt'] = (train['prompt']).apply(clean_text)\ntrain_cleaned['response_a'] = (train['response_a']).apply(clean_text)\ntrain_cleaned['response_b'] = (train['response_b']).apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:27:33.202532Z","iopub.execute_input":"2024-08-05T16:27:33.202802Z","iopub.status.idle":"2024-08-05T16:29:21.111090Z","shell.execute_reply.started":"2024-08-05T16:27:33.202780Z","shell.execute_reply":"2024-08-05T16:29:21.110179Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#same thing for test data\ntest_cleaned = test.copy()\ntest_cleaned['prompt'] = (test['prompt']).apply(clean_text)\ntest_cleaned['response_a'] = (test['response_a']).apply(clean_text)\ntest_cleaned['response_b'] = (test['response_b']).apply(clean_text)\ntest_ids = test_cleaned['id']\ntest_cleaned.pop('id')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.prompt.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.118167Z","iopub.execute_input":"2024-08-05T16:29:21.118470Z","iopub.status.idle":"2024-08-05T16:29:21.173690Z","shell.execute_reply.started":"2024-08-05T16:29:21.118446Z","shell.execute_reply":"2024-08-05T16:29:21.172745Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"252"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_a.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.174605Z","iopub.execute_input":"2024-08-05T16:29:21.174862Z","iopub.status.idle":"2024-08-05T16:29:21.224435Z","shell.execute_reply.started":"2024-08-05T16:29:21.174839Z","shell.execute_reply":"2024-08-05T16:29:21.223413Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_b.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.231525Z","iopub.execute_input":"2024-08-05T16:29:21.231826Z","iopub.status.idle":"2024-08-05T16:29:21.278033Z","shell.execute_reply.started":"2024-08-05T16:29:21.231801Z","shell.execute_reply":"2024-08-05T16:29:21.277097Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"270"},"metadata":{}}]},{"cell_type":"code","source":"train_df = train_cleaned[(train_cleaned.prompt.astype(str).str.len()>0) & (train_cleaned.response_a.astype(str).str.len()>0)& (train_cleaned.response_b.astype(str).str.len()>0)]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.279126Z","iopub.execute_input":"2024-08-05T16:29:21.279400Z","iopub.status.idle":"2024-08-05T16:29:21.405445Z","shell.execute_reply.started":"2024-08-05T16:29:21.279377Z","shell.execute_reply":"2024-08-05T16:29:21.404658Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.406501Z","iopub.execute_input":"2024-08-05T16:29:21.406788Z","iopub.status.idle":"2024-08-05T16:29:21.446170Z","shell.execute_reply.started":"2024-08-05T16:29:21.406764Z","shell.execute_reply":"2024-08-05T16:29:21.445306Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 56800 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              56800 non-null  int64 \n 1   model_a         56800 non-null  object\n 2   model_b         56800 non-null  object\n 3   prompt          56800 non-null  object\n 4   response_a      56800 non-null  object\n 5   response_b      56800 non-null  object\n 6   winner_model_a  56800 non-null  int64 \n 7   winner_model_b  56800 non-null  int64 \n 8   winner_tie      56800 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 4.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# getting the total vocab length for the trainset after cleaning/preprocessing and removing empty strings\ncombined_text2 = train_cleaned2['prompt'] + ' ' + train_cleaned2['response_a'] + ' ' + train_cleaned2['response_b']\ndata2 = combined_text2.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.447681Z","iopub.execute_input":"2024-08-05T16:29:21.447999Z","iopub.status.idle":"2024-08-05T16:29:21.452605Z","shell.execute_reply.started":"2024-08-05T16:29:21.447972Z","shell.execute_reply":"2024-08-05T16:29:21.451477Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"total_vocabulary2 = set(word for combined_text2 in data2 for word in combined_text2)\nprint(len(total_vocabulary2))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.453876Z","iopub.execute_input":"2024-08-05T16:29:21.454238Z","iopub.status.idle":"2024-08-05T16:29:21.462950Z","shell.execute_reply.started":"2024-08-05T16:29:21.454204Z","shell.execute_reply":"2024-08-05T16:29:21.461985Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('There are {} unique words in the dataset.'.format(len(total_vocabulary2)))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.464066Z","iopub.execute_input":"2024-08-05T16:29:21.464524Z","iopub.status.idle":"2024-08-05T16:29:21.474735Z","shell.execute_reply.started":"2024-08-05T16:29:21.464494Z","shell.execute_reply":"2024-08-05T16:29:21.473762Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"<em>After</em> cleaning and preprocessing the text features, the dataset contains 410,804 unique words. This is a huge improvement.","metadata":{}},{"cell_type":"markdown","source":"Removing any unnecessary features:","metadata":{}},{"cell_type":"code","source":"# The features 'model_a','model_b' are not in the test dataset, so I won't use these for modeling\n# Also, the ID feature won't add anything useful to our model so it's best to remove it so it doesn't confuse by adding extra info\n\ntrain_df.pop('model_a')\n\ntrain_df.pop('model_b')\n\ntrain_df.pop('id')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.475827Z","iopub.execute_input":"2024-08-05T16:29:21.476092Z","iopub.status.idle":"2024-08-05T16:29:21.495388Z","shell.execute_reply.started":"2024-08-05T16:29:21.476068Z","shell.execute_reply":"2024-08-05T16:29:21.494311Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0             30192\n1             53567\n2             65089\n3             96401\n4            198779\n            ...    \n57472    4294656694\n57473    4294692063\n57474    4294710549\n57475    4294899228\n57476    4294947231\nName: id, Length: 56800, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Train-test splitting the data:","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_, test_ = train_test_split(train_cleaned2, test_size=0.2, random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.496545Z","iopub.execute_input":"2024-08-05T16:29:21.496881Z","iopub.status.idle":"2024-08-05T16:29:21.504258Z","shell.execute_reply.started":"2024-08-05T16:29:21.496848Z","shell.execute_reply":"2024-08-05T16:29:21.503467Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"We need to create a target that includes all three of the outcomes we are trying to predict (winner_model_a, winner_model_b, winner_tie):","metadata":{}},{"cell_type":"code","source":"def target(data):\n    y1 = data.pop('winner_model_a')\n    y1 = np.array(y1)\n    y2 = data.pop('winner_model_b')\n    y2 = np.array(y2)\n    y3 = data.pop('winner_tie')\n    y3 = np.array(y3)\n    return y1, y2, y3\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.505575Z","iopub.execute_input":"2024-08-05T16:29:21.505870Z","iopub.status.idle":"2024-08-05T16:29:21.516050Z","shell.execute_reply.started":"2024-08-05T16:29:21.505845Z","shell.execute_reply":"2024-08-05T16:29:21.515024Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#format the outputs for both train and test sets\ntarget_train = target(train_df)\n\ntarget_test = target(test)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.517166Z","iopub.execute_input":"2024-08-05T16:29:21.517444Z","iopub.status.idle":"2024-08-05T16:29:21.529669Z","shell.execute_reply.started":"2024-08-05T16:29:21.517420Z","shell.execute_reply":"2024-08-05T16:29:21.528717Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"target_train= np.transpose(target_train)\ntarget_test= np.transpose(target_test)\ntarget_train","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.531039Z","iopub.execute_input":"2024-08-05T16:29:21.531892Z","iopub.status.idle":"2024-08-05T16:29:21.546272Z","shell.execute_reply.started":"2024-08-05T16:29:21.531856Z","shell.execute_reply":"2024-08-05T16:29:21.545336Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       ...,\n       [1, 0, 0],\n       [0, 1, 0],\n       [1, 0, 0]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Each of the input features need to be tokenized and vectorized, so that a model can interpret them:","metadata":{}},{"cell_type":"code","source":"print(train_df.prompt.str.len().max())\nprint(train_df.response_a.str.len().max())\nprint(train_df.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.547442Z","iopub.execute_input":"2024-08-05T16:29:21.547791Z","iopub.status.idle":"2024-08-05T16:29:21.679368Z","shell.execute_reply.started":"2024-08-05T16:29:21.547752Z","shell.execute_reply":"2024-08-05T16:29:21.678496Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"24848\n35411\n41202\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next, to make sure all the tokenized sequences are the same length, I'm going to pad them all to the length of the <strong>longest sequence</strong>. Any sequences shorter than that will be truncated to meet the size requirement.","metadata":{}},{"cell_type":"code","source":"vocab_size = 410804\nmax_seq_len = 2000\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\ntokenizer.fit_on_texts(train_df)\n\nprompt_sequences_train = tokenizer.texts_to_sequences(train_df['prompt'])\nresp_a_sequences_train = tokenizer.texts_to_sequences(train_df['response_a'])\nresp_b_sequences_train = tokenizer.texts_to_sequences(train_df['response_b'])\n\n\nprompt_train = pad_sequences(prompt_sequences_train, maxlen=max_seq_len, padding='post',truncating='post')\nresp_a_train = pad_sequences(resp_a_sequences_train, maxlen=max_seq_len, padding='post',truncating='post')\nresp_b_train = pad_sequences(resp_b_sequences_train, maxlen=max_seq_len, padding='post',truncating='post')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:29:21.755618Z","iopub.execute_input":"2024-08-05T16:29:21.755918Z","iopub.status.idle":"2024-08-05T16:29:35.239770Z","shell.execute_reply.started":"2024-08-05T16:29:21.755895Z","shell.execute_reply":"2024-08-05T16:29:35.238713Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# same thing to prepare the test dataset\nprompt_sequences_test = tokenizer.texts_to_sequences(test['prompt'])\nresp_a_sequences_test = tokenizer.texts_to_sequences(test['response_a'])\nresp_b_sequences_test = tokenizer.texts_to_sequences(test['response_b'])\n\n\nprompt_test = pad_sequences(prompt_sequences_test, maxlen=max_seq_len, padding='post',truncating='post')\nresp_a_test = pad_sequences(resp_a_sequences_test, maxlen=max_seq_len, padding='post',truncating='post')\nresp_b_test = pad_sequences(resp_b_sequences_test, maxlen=max_seq_len, padding='post',truncating='post')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"# tf.keras.backend.clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sequential model\n\n\ndef get_model():\n    model = Sequential()\n    model.add(Input(shape=(2000,)))\n\n    model.add(\n        Embedding(input_dim=410805,\n                  output_dim=150,\n                 mask_zero=True))\n    model.add(Masking(mask_value=0.))\n\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(LSTM(512,return_sequences=True))\n    model.add(LSTM(256))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(128,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(64,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(32,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n#     model.add(layers.Flatten())\n#     model.add(GlobalAveragePooling1D())\n    model.add(Dense(3,activation='softmax'))\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_seq = get_model()\nmodel_seq.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_seq.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=[keras.metrics.CategoricalAccuracy])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model_seq, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_seq.fit(\n    (prompt_train, resp_a_train, resp_b_train),\n    target_train,\n    validation_split = 0.2,\n#     callbacks=callbacks,\n    batch_size=64,\n    shuffle=True,\n    epochs=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Tuning","metadata":{}},{"cell_type":"code","source":"vocab_size = 410804\ndef model_builder(hp):\n    model = Sequential()\n    model.add(Input(shape=(2000,)))\n    \n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n\n    model.add(\n        Embedding(input_dim=vocab_size + 1, \n                    output_dim=hp_vector_size, \n                    mask_zero=True))\n    model.add(Masking(mask_value=0.))\n    \n    model.add(LayerNormalization())\n    \n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n\n   \n    model.add(Dropout(hp_dropout_rate))\n    \n    \n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    \n    model.add(LSTM(hp_lstm_units1,return_sequences=True))\n    \n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    \n    model.add(LSTM(hp_lstm_units2))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units1 = hp.Int('dense_units1', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units1,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units2 = hp.Int('dense_units2', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units2,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units3 = hp.Int('dense_units3', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units3,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    model.add(Dense(3,activation='softmax'))\n    \n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    \n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:30:41.395347Z","iopub.execute_input":"2024-08-05T16:30:41.395759Z","iopub.status.idle":"2024-08-05T16:30:41.410269Z","shell.execute_reply.started":"2024-08-05T16:30:41.395727Z","shell.execute_reply":"2024-08-05T16:30:41.409059Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"\ntuner = kt.Hyperband(model_builder,\n                     objective=kt.Objective(\"val_loss\", direction=\"min\"),\n                     max_epochs=3,\n                     factor=2\n                     )","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:30:42.743497Z","iopub.execute_input":"2024-08-05T16:30:42.744232Z","iopub.status.idle":"2024-08-05T16:30:42.764705Z","shell.execute_reply.started":"2024-08-05T16:30:42.744201Z","shell.execute_reply":"2024-08-05T16:30:42.763820Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner_callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                                  patience=2,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n    tf.keras.callbacks.ModelCheckpoint(\n                            f'../best_model.keras',\n                            save_best_only=True,\n                            monitor='val_loss',\n                            mode='min'\n                       )\n ]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:30:52.018706Z","iopub.execute_input":"2024-08-05T16:30:52.019086Z","iopub.status.idle":"2024-08-05T16:30:52.024540Z","shell.execute_reply.started":"2024-08-05T16:30:52.019057Z","shell.execute_reply":"2024-08-05T16:30:52.023776Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"\ntuner.search((prompt_train, resp_a_train, resp_b_train), \n             target_train, \n             epochs=1, \n             validation_split=0.2, \n             callbacks=tuner_callbacks\n             )\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:30:54.105900Z","iopub.execute_input":"2024-08-05T16:30:54.106504Z","iopub.status.idle":"2024-08-05T16:30:54.111982Z","shell.execute_reply.started":"2024-08-05T16:30:54.106472Z","shell.execute_reply":"2024-08-05T16:30:54.111023Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:31:09.319559Z","iopub.execute_input":"2024-08-05T16:31:09.320110Z","iopub.status.idle":"2024-08-05T16:31:09.325370Z","shell.execute_reply.started":"2024-08-05T16:31:09.320068Z","shell.execute_reply":"2024-08-05T16:31:09.324064Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                      \n                                  patience=5,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # This takes a long time to run, uncomment if needed\n# # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n# model_best_hp = tuner.hypermodel.build(best_hps)\n# callbacks = [\n#     keras.callbacks.EarlyStopping(monitor='val_loss',\n#                                   mode='min',\n#                                   patience=5,\n#                                   verbose=1,\n#                                   restore_best_weights=True)  \n# ]\n# history = model_best_hp.fit((prompt_train, resp_a_train, resp_b_train), \n#                             target_train, \n#                             epochs=15,\n#                             shuffle=True,\n#                             callbacks=callbacks,\n#                             batch_size=64,\n#                             validation_split=0.2)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:36:59.707490Z","iopub.execute_input":"2024-08-05T16:36:59.707935Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 749ms/step - categorical_accuracy: 0.3326 - loss: 2.2706 - val_categorical_accuracy: 0.3385 - val_loss: 1.0976\nEpoch 2/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 752ms/step - categorical_accuracy: 0.3428 - loss: 1.1046 - val_categorical_accuracy: 0.3385 - val_loss: 1.0975\nEpoch 3/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 751ms/step - categorical_accuracy: 0.3458 - loss: 1.1011 - val_categorical_accuracy: 0.3519 - val_loss: 1.0972\nEpoch 4/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 751ms/step - categorical_accuracy: 0.3393 - loss: 1.1001 - val_categorical_accuracy: 0.3386 - val_loss: 1.0976\nEpoch 5/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 752ms/step - categorical_accuracy: 0.3421 - loss: 1.1001 - val_categorical_accuracy: 0.3385 - val_loss: 1.0980\nEpoch 6/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 752ms/step - categorical_accuracy: 0.3419 - loss: 1.1007 - val_categorical_accuracy: 0.3519 - val_loss: 1.0973\nEpoch 7/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 753ms/step - categorical_accuracy: 0.3451 - loss: 1.0991 - val_categorical_accuracy: 0.3386 - val_loss: 1.0976\nEpoch 8/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 755ms/step - categorical_accuracy: 0.3496 - loss: 1.0987 - val_categorical_accuracy: 0.3520 - val_loss: 1.0972\nEpoch 9/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 755ms/step - categorical_accuracy: 0.3492 - loss: 1.0993 - val_categorical_accuracy: 0.3385 - val_loss: 1.0983\nEpoch 10/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 756ms/step - categorical_accuracy: 0.3429 - loss: 1.1001 - val_categorical_accuracy: 0.3520 - val_loss: 1.0973\nEpoch 11/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 763ms/step - categorical_accuracy: 0.3431 - loss: 1.0990 - val_categorical_accuracy: 0.3520 - val_loss: 1.0973\nEpoch 12/15\n\u001b[1m710/710\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 765ms/step - categorical_accuracy: 0.3510 - loss: 1.0988 - val_categorical_accuracy: 0.3520 - val_loss: 1.0973\nEpoch 13/15\n\u001b[1m457/710\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 709ms/step - categorical_accuracy: 0.3471 - loss: 1.0980","output_type":"stream"}]},{"cell_type":"code","source":"# Save model\nmodel_best_hp.save('./final_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restore model\nloaded_model = tf.keras.models.load_model('./final_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating predictions for the test dataframe:","metadata":{}},{"cell_type":"code","source":"# Run predict with restored model\npredictions_test = loaded_model.predict((prompt_test, resp_a_test, resp_b_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = loaded_model.predict(inverse_test_ds, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = DataFrame(test_preds, index=test_ids, columns=test.columns)\ndisplay(submission.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### Next Steps:","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}