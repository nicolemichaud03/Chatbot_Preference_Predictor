{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":6058,"sourceType":"modelInstanceVersion","modelInstanceId":4679,"modelId":2819}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Competition Notebook:\"LMSYS - Chatbot Arena Human Preference Predictions\"","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am conducting data exploration, analysis, and modeling in order to generate predictions for which Chatbot model will be preferred for a given prompt.","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Exploration","metadata":{}},{"cell_type":"markdown","source":"First, import necessary packages, and connect to kaggle to import competition dataset:","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T18:50:51.453548Z","iopub.execute_input":"2024-08-04T18:50:51.454217Z","iopub.status.idle":"2024-08-04T18:50:51.808611Z","shell.execute_reply.started":"2024-08-04T18:50:51.454180Z","shell.execute_reply":"2024-08-04T18:50:51.807677Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n/kaggle/input/lmsys-chatbot-arena/train.csv\n/kaggle/input/lmsys-chatbot-arena/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set(font_scale=2)\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.metrics import log_loss\nfrom keras.models import Model\nfrom nltk.stem import PorterStemmer, SnowballStemmer\n\n\nimport keras\nimport tensorflow as tf\nfrom keras.utils import normalize, to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, TextVectorization, Softmax, LayerNormalization, Masking\nfrom keras.models import Sequential\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.preprocessing import sequence\nimport keras_tuner as kt\n\n# to avoid warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:51.809825Z","iopub.execute_input":"2024-08-04T18:50:51.810173Z","iopub.status.idle":"2024-08-04T18:50:56.004365Z","shell.execute_reply.started":"2024-08-04T18:50:51.810147Z","shell.execute_reply":"2024-08-04T18:50:56.003572Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"2024-08-04 18:50:53.181520: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-04 18:50:53.181581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-04 18:50:53.183060: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:56.005380Z","iopub.execute_input":"2024-08-04T18:50:56.005923Z","iopub.status.idle":"2024-08-04T18:50:56.010248Z","shell.execute_reply.started":"2024-08-04T18:50:56.005895Z","shell.execute_reply":"2024-08-04T18:50:56.009200Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Loading and exploring the train and test datasets:","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:56.014200Z","iopub.execute_input":"2024-08-04T18:50:56.014523Z","iopub.status.idle":"2024-08-04T18:50:57.762719Z","shell.execute_reply.started":"2024-08-04T18:50:56.014497Z","shell.execute_reply":"2024-08-04T18:50:57.761844Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.763918Z","iopub.execute_input":"2024-08-04T18:50:57.764261Z","iopub.status.idle":"2024-08-04T18:50:57.780042Z","shell.execute_reply.started":"2024-08-04T18:50:57.764223Z","shell.execute_reply":"2024-08-04T18:50:57.778952Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.781400Z","iopub.execute_input":"2024-08-04T18:50:57.782135Z","iopub.status.idle":"2024-08-04T18:50:57.792180Z","shell.execute_reply.started":"2024-08-04T18:50:57.782096Z","shell.execute_reply":"2024-08-04T18:50:57.791225Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.835257Z","iopub.execute_input":"2024-08-04T18:50:57.835527Z","iopub.status.idle":"2024-08-04T18:50:57.871679Z","shell.execute_reply.started":"2024-08-04T18:50:57.835502Z","shell.execute_reply":"2024-08-04T18:50:57.870707Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.873030Z","iopub.execute_input":"2024-08-04T18:50:57.873714Z","iopub.status.idle":"2024-08-04T18:50:57.896228Z","shell.execute_reply.started":"2024-08-04T18:50:57.873681Z","shell.execute_reply":"2024-08-04T18:50:57.895399Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"I'm interested to see what models are winning most often in the datasets:","metadata":{}},{"cell_type":"code","source":"winner_a = train[train['winner_model_a']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.897331Z","iopub.execute_input":"2024-08-04T18:50:57.897709Z","iopub.status.idle":"2024-08-04T18:50:57.906159Z","shell.execute_reply.started":"2024-08-04T18:50:57.897670Z","shell.execute_reply":"2024-08-04T18:50:57.905257Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"winner_b = train[train['winner_model_b']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.907227Z","iopub.execute_input":"2024-08-04T18:50:57.907476Z","iopub.status.idle":"2024-08-04T18:50:57.914705Z","shell.execute_reply.started":"2024-08-04T18:50:57.907453Z","shell.execute_reply":"2024-08-04T18:50:57.913688Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"winner_a['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.915753Z","iopub.execute_input":"2024-08-04T18:50:57.916098Z","iopub.status.idle":"2024-08-04T18:50:57.926659Z","shell.execute_reply.started":"2024-08-04T18:50:57.916070Z","shell.execute_reply":"2024-08-04T18:50:57.925691Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"model_a\ngpt-4-1106-preview          2019\ngpt-4-0613                  1280\ngpt-3.5-turbo-0613          1213\ngpt-4-0314                  1033\nclaude-2.1                   896\n                            ... \nchatglm2-6b                   35\nqwen1.5-7b-chat               29\nopenchat-3.5-0106             28\nqwen1.5-4b-chat               19\nmistral-7b-instruct-v0.2      15\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"winner_b['model_b'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.931551Z","iopub.execute_input":"2024-08-04T18:50:57.931826Z","iopub.status.idle":"2024-08-04T18:50:57.941615Z","shell.execute_reply.started":"2024-08-04T18:50:57.931803Z","shell.execute_reply":"2024-08-04T18:50:57.940692Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"model_b\ngpt-4-1106-preview          2054\ngpt-4-0613                  1170\ngpt-3.5-turbo-0613          1168\ngpt-4-0314                   960\nclaude-1                     880\n                            ... \nchatglm2-6b                   38\nopenchat-3.5-0106             35\nqwen1.5-7b-chat               22\nqwen1.5-4b-chat               16\nmistral-7b-instruct-v0.2      12\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The top 4 models that won most often as model a or as model b are:\n- gpt-4-1106-preview\n- gpt-4-0613\n- gpt-3.5-turbo-0613\n- gpt-4-0314","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Since the 'prompt', 'response_a', and 'response_b' features are text, they need to be cleaned and pre-processed before they are tokenized and vectorized.","metadata":{}},{"cell_type":"code","source":"# Need to make sure the relevant features are all in string format\n\ntrain['prompt'] = train['prompt'].astype(str)\ntrain['response_a'] = train['response_a'].astype(str)\ntrain['response_b'] = train['response_b'].astype(str)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.942883Z","iopub.execute_input":"2024-08-04T18:50:57.943478Z","iopub.status.idle":"2024-08-04T18:50:57.956328Z","shell.execute_reply.started":"2024-08-04T18:50:57.943445Z","shell.execute_reply":"2024-08-04T18:50:57.955525Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # getting the total vocab length before text cleaning/preprocessing\n# combined_text1 = train['prompt'] + ' ' + train['response_a'] + ' ' + train['response_b']\n# data1 = combined_text1.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.957457Z","iopub.execute_input":"2024-08-04T18:50:57.957887Z","iopub.status.idle":"2024-08-04T18:50:57.961952Z","shell.execute_reply.started":"2024-08-04T18:50:57.957855Z","shell.execute_reply":"2024-08-04T18:50:57.960972Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary1 = set(word for combined_text1 in data1 for word in combined_text1)\n# print(len(total_vocabulary1))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.963139Z","iopub.execute_input":"2024-08-04T18:50:57.963949Z","iopub.status.idle":"2024-08-04T18:50:57.970428Z","shell.execute_reply.started":"2024-08-04T18:50:57.963916Z","shell.execute_reply":"2024-08-04T18:50:57.969460Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary1)))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.971571Z","iopub.execute_input":"2024-08-04T18:50:57.971906Z","iopub.status.idle":"2024-08-04T18:50:57.977842Z","shell.execute_reply.started":"2024-08-04T18:50:57.971882Z","shell.execute_reply":"2024-08-04T18:50:57.976999Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Before cleaning and preprocessing the text features, the dataset contains 942,074 unique words.","metadata":{}},{"cell_type":"code","source":"# Creating a function to perform cleaning steps at once (Removes numbers and unnecessary characters, makes all letters lowercase, removes stopwords)\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\nno_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\nno_nums = re.compile('[\\d-]')\n\ndef clean_text(text):\n    text = no_nums.sub('', text)\n    text = no_bad_chars.sub(' ', text)\n    text = text.lower()\n    text = stemmer.stem(text)\n    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n\n    return text\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.978924Z","iopub.execute_input":"2024-08-04T18:50:57.979203Z","iopub.status.idle":"2024-08-04T18:50:57.992050Z","shell.execute_reply.started":"2024-08-04T18:50:57.979181Z","shell.execute_reply":"2024-08-04T18:50:57.990969Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#Applying text cleaning function to text columns\ntrain_cleaned = train.copy()\ntrain_cleaned['prompt'] = (train['prompt']).apply(clean_text)\ntrain_cleaned['response_a'] = (train['response_a']).apply(clean_text)\ntrain_cleaned['response_b'] = (train['response_b']).apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:50:57.993115Z","iopub.execute_input":"2024-08-04T18:50:57.993445Z","iopub.status.idle":"2024-08-04T18:52:45.295351Z","shell.execute_reply.started":"2024-08-04T18:50:57.993412Z","shell.execute_reply":"2024-08-04T18:52:45.294269Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# train_cleaned['winner_model_a'] = train['winner_model_a']\n# train_cleaned['winner_model_b'] = train['winner_model_b']\n# train_cleaned['winner_tie'] = train['winner_tie']","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.296613Z","iopub.execute_input":"2024-08-04T18:52:45.297011Z","iopub.status.idle":"2024-08-04T18:52:45.301325Z","shell.execute_reply.started":"2024-08-04T18:52:45.296977Z","shell.execute_reply":"2024-08-04T18:52:45.300308Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.prompt.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.302554Z","iopub.execute_input":"2024-08-04T18:52:45.302900Z","iopub.status.idle":"2024-08-04T18:52:45.350797Z","shell.execute_reply.started":"2024-08-04T18:52:45.302865Z","shell.execute_reply":"2024-08-04T18:52:45.349991Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"252"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_a.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.351823Z","iopub.execute_input":"2024-08-04T18:52:45.352081Z","iopub.status.idle":"2024-08-04T18:52:45.398629Z","shell.execute_reply.started":"2024-08-04T18:52:45.352058Z","shell.execute_reply":"2024-08-04T18:52:45.397785Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_b.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.399886Z","iopub.execute_input":"2024-08-04T18:52:45.400506Z","iopub.status.idle":"2024-08-04T18:52:45.445303Z","shell.execute_reply.started":"2024-08-04T18:52:45.400472Z","shell.execute_reply":"2024-08-04T18:52:45.444415Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"270"},"metadata":{}}]},{"cell_type":"code","source":"train_df = train_cleaned[(train_cleaned.prompt.astype(str).str.len()>0) & (train_cleaned.response_a.astype(str).str.len()>0)& (train_cleaned.response_b.astype(str).str.len()>0)]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.446440Z","iopub.execute_input":"2024-08-04T18:52:45.446761Z","iopub.status.idle":"2024-08-04T18:52:45.565874Z","shell.execute_reply.started":"2024-08-04T18:52:45.446728Z","shell.execute_reply":"2024-08-04T18:52:45.565044Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.567157Z","iopub.execute_input":"2024-08-04T18:52:45.567771Z","iopub.status.idle":"2024-08-04T18:52:45.606056Z","shell.execute_reply.started":"2024-08-04T18:52:45.567736Z","shell.execute_reply":"2024-08-04T18:52:45.605125Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 56800 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              56800 non-null  int64 \n 1   model_a         56800 non-null  object\n 2   model_b         56800 non-null  object\n 3   prompt          56800 non-null  object\n 4   response_a      56800 non-null  object\n 5   response_b      56800 non-null  object\n 6   winner_model_a  56800 non-null  int64 \n 7   winner_model_b  56800 non-null  int64 \n 8   winner_tie      56800 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 4.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# # getting the total vocab length for the trainset after cleaning/preprocessing and removing empty strings\n# combined_text2 = train_cleaned2['prompt'] + ' ' + train_cleaned2['response_a'] + ' ' + train_cleaned2['response_b']\n# data2 = combined_text2.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.607042Z","iopub.execute_input":"2024-08-04T18:52:45.607304Z","iopub.status.idle":"2024-08-04T18:52:45.611211Z","shell.execute_reply.started":"2024-08-04T18:52:45.607280Z","shell.execute_reply":"2024-08-04T18:52:45.610294Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary2 = set(word for combined_text2 in data2 for word in combined_text2)\n# print(len(total_vocabulary2))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.612382Z","iopub.execute_input":"2024-08-04T18:52:45.612790Z","iopub.status.idle":"2024-08-04T18:52:45.618863Z","shell.execute_reply.started":"2024-08-04T18:52:45.612744Z","shell.execute_reply":"2024-08-04T18:52:45.617967Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary2)))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.619937Z","iopub.execute_input":"2024-08-04T18:52:45.620253Z","iopub.status.idle":"2024-08-04T18:52:45.626014Z","shell.execute_reply.started":"2024-08-04T18:52:45.620228Z","shell.execute_reply":"2024-08-04T18:52:45.625155Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"<em>After</em> cleaning and preprocessing the text features, the dataset contains 410,804 unique words. This is a huge improvement.","metadata":{}},{"cell_type":"markdown","source":"Removing any unnecessary features:","metadata":{}},{"cell_type":"code","source":"# The features 'model_a','model_b' are not in the test dataset, so I won't use these for modeling\n# Also, the ID feature won't add anything useful to our model so it's best to remove it so it doesn't confuse by adding extra info\n\ntrain_df.pop('model_a')\n\ntrain_df.pop('model_b')\n\ntrain_df.pop('id')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.626996Z","iopub.execute_input":"2024-08-04T18:52:45.627285Z","iopub.status.idle":"2024-08-04T18:52:45.640212Z","shell.execute_reply.started":"2024-08-04T18:52:45.627260Z","shell.execute_reply":"2024-08-04T18:52:45.639244Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0             30192\n1             53567\n2             65089\n3             96401\n4            198779\n            ...    \n57472    4294656694\n57473    4294692063\n57474    4294710549\n57475    4294899228\n57476    4294947231\nName: id, Length: 56800, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Train-test splitting the data:","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# train_, test_ = train_test_split(train_cleaned2, test_size=0.2, random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.644631Z","iopub.execute_input":"2024-08-04T18:52:45.644929Z","iopub.status.idle":"2024-08-04T18:52:45.648480Z","shell.execute_reply.started":"2024-08-04T18:52:45.644905Z","shell.execute_reply":"2024-08-04T18:52:45.647543Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"We need to create a target that includes all three of the outcomes we are trying to predict (winner_model_a, winner_model_b, winner_tie):","metadata":{}},{"cell_type":"code","source":"def target(data):\n    y1 = data.pop('winner_model_a')\n    y1 = np.array(y1)\n    y2 = data.pop('winner_model_b')\n    y2 = np.array(y2)\n    y3 = data.pop('winner_tie')\n    y3 = np.array(y3)\n    return y1, y2, y3\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.649663Z","iopub.execute_input":"2024-08-04T18:52:45.649943Z","iopub.status.idle":"2024-08-04T18:52:45.655979Z","shell.execute_reply.started":"2024-08-04T18:52:45.649919Z","shell.execute_reply":"2024-08-04T18:52:45.655007Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#format the outputs for both train and test sets\ntarget_train = target(train_df)\n\n# target_test = target(test_)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.657115Z","iopub.execute_input":"2024-08-04T18:52:45.657435Z","iopub.status.idle":"2024-08-04T18:52:45.664707Z","shell.execute_reply.started":"2024-08-04T18:52:45.657401Z","shell.execute_reply":"2024-08-04T18:52:45.663853Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"target_train= np.transpose(target_train)\n# target_test= np.transpose(target_test)\ntarget_train","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:45.665951Z","iopub.execute_input":"2024-08-04T18:52:45.666287Z","iopub.status.idle":"2024-08-04T18:52:45.674580Z","shell.execute_reply.started":"2024-08-04T18:52:45.666243Z","shell.execute_reply":"2024-08-04T18:52:45.673703Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 1],\n       ...,\n       [1, 0, 0],\n       [0, 1, 0],\n       [1, 0, 0]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Each of the input features need to be tokenized and vectorized, so that a model can interpret them:","metadata":{}},{"cell_type":"code","source":"print(train_df.prompt.str.len().max())\nprint(train_df.response_a.str.len().max())\nprint(train_df.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:53:43.452673Z","iopub.execute_input":"2024-08-04T18:53:43.453071Z","iopub.status.idle":"2024-08-04T18:53:43.575943Z","shell.execute_reply.started":"2024-08-04T18:53:43.453042Z","shell.execute_reply":"2024-08-04T18:53:43.574868Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"24848\n35411\n41202\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(test_.prompt.str.len().max())\n# print(test_.response_a.str.len().max())\n# print(test_.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:46.408048Z","iopub.status.idle":"2024-08-04T18:52:46.408374Z","shell.execute_reply.started":"2024-08-04T18:52:46.408213Z","shell.execute_reply":"2024-08-04T18:52:46.408227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=410804)\n\n# tokenizer.fit_on_texts(list(train_))\n# tokenized_tr = tokenizer.texts_to_sequences(train_)\n\n# tokenized_te = tokenizer.texts_to_sequences(test_)\n ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:52:46.409524Z","iopub.status.idle":"2024-08-04T18:52:46.409887Z","shell.execute_reply.started":"2024-08-04T18:52:46.409717Z","shell.execute_reply":"2024-08-04T18:52:46.409732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, to make sure all the tokenized sequences are the same length, I'm going to pad them all to the length of the <strong>longest sequence</strong>. Any sequences shorter than that will be truncated to meet the size requirement.","metadata":{}},{"cell_type":"code","source":"# max_seq_len = 35411\n# X_train = sequence.pad_sequences(tokenized_tr, maxlen=max_seq_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.shape(target_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# max_seq_len = 35411\n# X_test = sequence.pad_sequences(tokenized_te, maxlen=max_seq_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = np.transpose(X_train)\n# X_test = np.transpose(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 410804\nmax_seq_len = 41202\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\ntokenizer.fit_on_texts(train_df)\n\nsequences_train = tokenizer.texts_to_sequences(train_df)\n# sequences_test = tokenizer.texts_to_sequences(test_)\n\npadded_train = pad_sequences(sequences_train, maxlen=max_seq_len, padding='post',truncating='post')\n# padded_test = pad_sequences(sequences_test, maxlen=max_seq_len, padding='post', truncating='post')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:04.149121Z","iopub.execute_input":"2024-08-04T18:54:04.149854Z","iopub.status.idle":"2024-08-04T18:54:04.155670Z","shell.execute_reply.started":"2024-08-04T18:54:04.149820Z","shell.execute_reply":"2024-08-04T18:54:04.154625Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# demonstrate data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n# load data\ndata1 = padded_train\n# data2 = padded_test\n# create scaler\nscaler = MinMaxScaler()\n# fit and transform in one step\nnormalized_train = scaler.fit_transform(data1)\n# normalized_test = scaler.fit_transform(data2)\n\n# inverse transform\ninverse_train = scaler.inverse_transform(normalized_train)\n# inverse_test = scaler.inverse_transform(normalized_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:06.915824Z","iopub.execute_input":"2024-08-04T18:54:06.916495Z","iopub.status.idle":"2024-08-04T18:54:06.925289Z","shell.execute_reply.started":"2024-08-04T18:54:06.916461Z","shell.execute_reply":"2024-08-04T18:54:06.924301Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# # load data\n# data1 = X_train\n# data2 = X_test\n# # create scaler\n# scaler = StandardScaler()\n# # fit and transform in one step\n# standardized_train = scaler.fit_transform(data1)\n# standardized_test = scaler.fit_transform(data2)\n# # inverse transform\n# inverse_train = scaler.inverse_transform(standardized_train)\n# inverse_test = scaler.inverse_transform(standardized_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:07.930114Z","iopub.execute_input":"2024-08-04T18:54:07.930481Z","iopub.status.idle":"2024-08-04T18:54:07.935040Z","shell.execute_reply.started":"2024-08-04T18:54:07.930450Z","shell.execute_reply":"2024-08-04T18:54:07.934102Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# padded_train = np.transpose(padded_train)\n# padded_test = np.transpose(padded_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:08.441974Z","iopub.execute_input":"2024-08-04T18:54:08.442334Z","iopub.status.idle":"2024-08-04T18:54:08.446753Z","shell.execute_reply.started":"2024-08-04T18:54:08.442307Z","shell.execute_reply":"2024-08-04T18:54:08.445660Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"inverse_train = np.transpose(inverse_train)\n# inverse_test = np.transpose(inverse_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:09.141006Z","iopub.execute_input":"2024-08-04T18:54:09.141303Z","iopub.status.idle":"2024-08-04T18:54:09.145528Z","shell.execute_reply.started":"2024-08-04T18:54:09.141278Z","shell.execute_reply":"2024-08-04T18:54:09.144485Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                      \n                                  patience=5,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n ]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:12.314080Z","iopub.execute_input":"2024-08-04T18:54:12.314939Z","iopub.status.idle":"2024-08-04T18:54:12.319603Z","shell.execute_reply.started":"2024-08-04T18:54:12.314905Z","shell.execute_reply":"2024-08-04T18:54:12.318524Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:12.960984Z","iopub.execute_input":"2024-08-04T18:54:12.961622Z","iopub.status.idle":"2024-08-04T18:54:13.159729Z","shell.execute_reply.started":"2024-08-04T18:54:12.961593Z","shell.execute_reply":"2024-08-04T18:54:13.158791Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#sequential model\n\n\ndef get_model():\n    model = Sequential()\n    model.add(Input(shape=(3,)))\n\n    model.add(\n        Embedding(input_dim=410805,\n                  output_dim=150,\n                 mask_zero=True))\n    model.add(Masking(mask_value=0.))\n\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(LSTM(512,return_sequences=True))\n    model.add(LSTM(256))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(128,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(64,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(32,activation='relu'))\n    model.add(LayerNormalization())\n    model.add(Dropout(0.8))\n    model.add(layers.Flatten())\n    model.add(Dense(3,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:13.945805Z","iopub.execute_input":"2024-08-04T18:54:13.946132Z","iopub.status.idle":"2024-08-04T18:54:13.954915Z","shell.execute_reply.started":"2024-08-04T18:54:13.946103Z","shell.execute_reply":"2024-08-04T18:54:13.953985Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model_seq = get_model()\nmodel_seq.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:15.285124Z","iopub.execute_input":"2024-08-04T18:54:15.286177Z","iopub.status.idle":"2024-08-04T18:54:16.938846Z","shell.execute_reply.started":"2024-08-04T18:54:15.286129Z","shell.execute_reply":"2024-08-04T18:54:16.937917Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │    \u001b[38;5;34m61,620,750\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │           \u001b[38;5;34m300\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m1,357,824\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">61,620,750</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,357,824</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,810,621\u001b[0m (243.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,810,621</span> (243.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,810,621\u001b[0m (243.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,810,621</span> (243.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_seq.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=[keras.metrics.CategoricalAccuracy])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:16.940434Z","iopub.execute_input":"2024-08-04T18:54:16.940740Z","iopub.status.idle":"2024-08-04T18:54:16.954412Z","shell.execute_reply.started":"2024-08-04T18:54:16.940714Z","shell.execute_reply":"2024-08-04T18:54:16.953693Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# keras.utils.plot_model(model_seq, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:16.955547Z","iopub.execute_input":"2024-08-04T18:54:16.955925Z","iopub.status.idle":"2024-08-04T18:54:16.960267Z","shell.execute_reply.started":"2024-08-04T18:54:16.955893Z","shell.execute_reply":"2024-08-04T18:54:16.959371Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model_seq.fit(\n    inverse_train,\n    target_train,\n    validation_split = 0.2,\n#     callbacks=callbacks,\n    batch_size=64,\n    shuffle=True,\n    epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:54:16.962007Z","iopub.execute_input":"2024-08-04T18:54:16.962269Z","iopub.status.idle":"2024-08-04T18:58:10.272855Z","shell.execute_reply.started":"2024-08-04T18:54:16.962246Z","shell.execute_reply":"2024-08-04T18:58:10.271867Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 45ms/step - categorical_accuracy: 0.3388 - loss: 2.0094 - val_categorical_accuracy: 0.3354 - val_loss: 1.1003\nEpoch 2/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - categorical_accuracy: 0.3311 - loss: 1.1244 - val_categorical_accuracy: 0.3354 - val_loss: 1.0985\nEpoch 3/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - categorical_accuracy: 0.3440 - loss: 1.1016 - val_categorical_accuracy: 0.3354 - val_loss: 1.0978\nEpoch 4/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - categorical_accuracy: 0.3457 - loss: 1.0989 - val_categorical_accuracy: 0.3506 - val_loss: 1.0978\nEpoch 5/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - categorical_accuracy: 0.3500 - loss: 1.0991 - val_categorical_accuracy: 0.3354 - val_loss: 1.0981\nEpoch 6/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - categorical_accuracy: 0.3479 - loss: 1.0983 - val_categorical_accuracy: 0.3354 - val_loss: 1.0984\nEpoch 7/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - categorical_accuracy: 0.3435 - loss: 1.0989 - val_categorical_accuracy: 0.3354 - val_loss: 1.0982\nEpoch 8/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - categorical_accuracy: 0.3483 - loss: 1.0984 - val_categorical_accuracy: 0.3354 - val_loss: 1.0982\nEpoch 9/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - categorical_accuracy: 0.3504 - loss: 1.0987 - val_categorical_accuracy: 0.3354 - val_loss: 1.0982\nEpoch 10/10\n\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - categorical_accuracy: 0.3440 - loss: 1.0986 - val_categorical_accuracy: 0.3354 - val_loss: 1.0981\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x796d3c2ca830>"},"metadata":{}}]},{"cell_type":"code","source":"# preds_seq = model_seq.predict(inverse_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:58:10.274176Z","iopub.execute_input":"2024-08-04T18:58:10.274959Z","iopub.status.idle":"2024-08-04T18:58:10.280241Z","shell.execute_reply.started":"2024-08-04T18:58:10.274921Z","shell.execute_reply":"2024-08-04T18:58:10.279038Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# preds_seq[:30]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:58:57.941432Z","iopub.execute_input":"2024-08-04T18:58:57.942339Z","iopub.status.idle":"2024-08-04T18:58:57.946508Z","shell.execute_reply.started":"2024-08-04T18:58:57.942304Z","shell.execute_reply":"2024-08-04T18:58:57.945530Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Model Tuning","metadata":{}},{"cell_type":"code","source":"def model_builder(hp):\n    model = Sequential()\n    model.add(Input(shape=(3,)))\n    \n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n\n    model.add(\n        Embedding(input_dim=vocab_size + 1, \n                    output_dim=hp_vector_size, \n                    mask_zero=True))\n    model.add(Masking(mask_value=0.))\n    \n    model.add(LayerNormalization())\n    \n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n\n   \n    model.add(Dropout(hp_dropout_rate))\n    \n    \n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    \n    model.add(LSTM(hp_lstm_units1,return_sequences=True))\n    \n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    \n    model.add(LSTM(hp_lstm_units2))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units1 = hp.Int('dense_units1', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units1,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units2 = hp.Int('dense_units2', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units2,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    hp_dense_units3 = hp.Int('dense_units3', \n                            min_value=32, \n                            max_value=128, \n                            step=64)\n    \n    model.add(Dense(hp_dense_units3,activation='relu'))\n    \n    model.add(LayerNormalization())\n    \n    model.add(Dropout(hp_dropout_rate))\n    \n    model.add(Dense(3,activation='softmax'))\n    \n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    \n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:58:58.541909Z","iopub.execute_input":"2024-08-04T18:58:58.542790Z","iopub.status.idle":"2024-08-04T18:58:58.556266Z","shell.execute_reply.started":"2024-08-04T18:58:58.542755Z","shell.execute_reply":"2024-08-04T18:58:58.555230Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# vocab_size = 410804\n\n# def model_builder(hp):\n#     input_ = Input(shape=(3,))\n#     hp_vector_size = hp.Int('vector_size', \n#                             min_value=100, \n#                             max_value=500, \n#                             step=100)\n    \n#     em =  Embedding(input_dim=vocab_size + 1, \n#                     output_dim=hp_vector_size, \n#                     mask_zero=True)\n#     emb_input = emb(input_)\n    \n#     hp_dropout_rate = hp.Float('dropout_rate', \n#                                min_value=0.6, \n#                                max_value=0.9, \n#                                step=0.3)\n#     dropout = Dropout(hp_dropout_rate)(emb_input)\n    \n#     hp_lstm_units1 = hp.Int('lstm_units1', \n#                             min_value=32, \n#                             max_value=512, \n#                             step=64)\n#     lstm = LSTM(hp_lstm_units1,return_sequences=True)(dropout)\n    \n#     hp_lstm_units2 = hp.Int('lstm_units2', \n#                             min_value=16, \n#                             max_value=512, \n#                             step=64)\n#     lstm = LSTM(hp_lstm_units2)(dropout)\n    \n#     out = Dense(3,activation='softmax')(lstm)\n    \n#     hp_learning_rate = hp.Choice('learning_rate', \n#                                  values=[1e-2, 1e-3, 1e-4])\n#     model = keras.Model(input_,out)\n    \n#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n#                   loss='categorical_crossentropy',\n#                   metrics=[tf.keras.metrics.CategoricalAccuracy])\n#     return model","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:58:59.033970Z","iopub.execute_input":"2024-08-04T18:58:59.034780Z","iopub.status.idle":"2024-08-04T18:58:59.039564Z","shell.execute_reply.started":"2024-08-04T18:58:59.034745Z","shell.execute_reply":"2024-08-04T18:58:59.038716Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# vocab_size = 400000\n\n# def model_builder(hp):\n#     model = Sequential()\n#     hp_vector_size = hp.Int('vector_size', \n#                             min_value=100, \n#                             max_value=500, \n#                             step=150)\n#     model.add(\n#         Embedding(input_dim=vocab_size,\n#                   output_dim=150\n# #                   input_length=max_seq_len\n#                  ))\n#     hp_dropout_rate = hp.Float('dropout_rate', \n#                                min_value=0.6, \n#                                max_value=0.9, \n#                                step=0.3)\n#     model.add(Dropout(hp_dropout_rate))\n#     hp_lstm_units1 = hp.Int('lstm_units1', \n#                             min_value=32, \n#                             max_value=512, \n#                             step=64)\n#     model.add(LSTM(hp_lstm_units1,return_sequences=True))\n#     hp_lstm_units2 = hp.Int('lstm_units2', \n#                             min_value=16, \n#                             max_value=512, \n#                             step=64)\n#     model.add(LSTM(hp_lstm_units2))\n#     model.add(Dense(3,activation='softmax'))\n#     hp_learning_rate = hp.Choice('learning_rate', \n#                                  values=[1e-2, 1e-3, 1e-4])\n#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n#                   loss='categorical_crossentropy',\n#                   metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n#     return model","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:59:01.820667Z","iopub.execute_input":"2024-08-04T18:59:01.821265Z","iopub.status.idle":"2024-08-04T18:59:01.826567Z","shell.execute_reply.started":"2024-08-04T18:59:01.821234Z","shell.execute_reply":"2024-08-04T18:59:01.825538Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"\ntuner = kt.Hyperband(model_builder,\n                     objective=kt.Objective(\"val_loss\", direction=\"min\"),\n                     max_epochs=3,\n                     factor=2\n                     )","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:59:02.224357Z","iopub.execute_input":"2024-08-04T18:59:02.224840Z","iopub.status.idle":"2024-08-04T18:59:02.458966Z","shell.execute_reply.started":"2024-08-04T18:59:02.224814Z","shell.execute_reply":"2024-08-04T18:59:02.458172Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n# best_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n#                             f'../Results/{directory}/{project_name}/best_model.hdf5',\n#                             save_best_only=True,\n#                             monitor='val_loss',\n#                             mode='min'\n#                        )\n\ntuner_callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                                  patience=2,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n    tf.keras.callbacks.ModelCheckpoint(\n                            f'../best_model.keras',\n                            save_best_only=True,\n                            monitor='val_loss',\n                            mode='min'\n                       )\n ]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T18:59:05.522885Z","iopub.execute_input":"2024-08-04T18:59:05.523255Z","iopub.status.idle":"2024-08-04T18:59:05.529135Z","shell.execute_reply.started":"2024-08-04T18:59:05.523227Z","shell.execute_reply":"2024-08-04T18:59:05.528158Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"\ntuner.search(inverse_train, \n             target_train, \n             epochs=1, \n             validation_split=0.2, \n             callbacks=tuner_callbacks\n             )\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T19:00:01.635910Z","iopub.execute_input":"2024-08-04T19:00:01.636312Z","iopub.status.idle":"2024-08-04T19:20:34.724189Z","shell.execute_reply.started":"2024-08-04T19:00:01.636281Z","shell.execute_reply":"2024-08-04T19:20:34.723218Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Trial 8 Complete [00h 01m 56s]\nval_loss: 1.097900152206421\n\nBest val_loss So Far: 1.09775972366333\nTotal elapsed time: 00h 20m 33s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T19:20:42.504351Z","iopub.execute_input":"2024-08-04T19:20:42.504741Z","iopub.status.idle":"2024-08-04T19:20:42.509741Z","shell.execute_reply.started":"2024-08-04T19:20:42.504711Z","shell.execute_reply":"2024-08-04T19:20:42.508834Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"\n# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\nmodel_best_hp = tuner.hypermodel.build(best_hps)\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor='val_loss',\n                                  mode='min',\n                                  patience=5,\n                                  verbose=1,\n                                  restore_best_weights=True)  \n]\nhistory = model_best_hp.fit(inverse_train, \n                            target_train, \n                            epochs=15,\n                            callbacks=callbacks,\n                            validation_split=0.2)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nmodel_best_hp.save('./final_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restore model\nloaded_model = tf.keras.models.load_model('./final_model.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run predict with restored model\npredictions = loaded_model.predict(inverse_test)\nwinner_model_a = predictions[0]\nwinner_model_b = predictions[1]\nwinner_tie = predictions[2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating predictions for the test dataframe:","metadata":{}},{"cell_type":"code","source":"# Prepare the test dataset for making predictions\n\n# test_texts = test_df.options.tolist()\n# test_ds = build_dataset(test_texts,\n#                          batch_size=min(len(test_df), CFG.batch_size),\n#                          shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head( )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Need to make sure the relevant features are all in string format\n\ntest['prompt'] = test['prompt'].astype(str)\ntest['response_a'] = test['response_a'].astype(str)\ntest['response_b'] = test['response_b'].astype(str)\n     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cleaned = test.copy()\ntest_cleaned['prompt'] = (test['prompt']).apply(clean_text)\ntest_cleaned['response_a'] = (test['response_a']).apply(clean_text)\ntest_cleaned['response_b'] = (test['response_b']).apply(clean_text)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsequences_test_ds = tokenizer.texts_to_sequences(test)\n\npadded_test_ds = pad_sequences(sequences_test_ds, maxlen=max_seq_len, padding='post', truncating='post')\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# demonstrate data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n# load data\ndata_test = padded_test_ds\n\n# create scaler\nscaler = MinMaxScaler()\n# fit and transform in one step\nnormalized_test_ds = scaler.fit_transform(data_test)\n\n# inverse transform\ninverse_test_ds = scaler.inverse_transform(normalized_test_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run predict with restored model\npredictions_test = loaded_model.predict(inverse_test)\nwinner_model_a = predictions[0]\nwinner_model_b = predictions[1]\nwinner_tie = predictions[2]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(test_ds, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing submission\nsubmission = test[[\"id\"]].copy()\nsubmission[CFG.class_names] = test_preds.tolist()\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}