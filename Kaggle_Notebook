{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Competition Notebook:\"LMSYS - Chatbot Arena Human Preference Predictions\"","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am conducting data exploration, analysis, and modeling in order to generate predictions for which Chatbot model will be preferred for a given prompt.","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Exploration","metadata":{}},{"cell_type":"markdown","source":"First, import necessary packages, and connect to kaggle to import competition dataset:","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-03T18:15:49.948222Z","iopub.execute_input":"2024-08-03T18:15:49.948703Z","iopub.status.idle":"2024-08-03T18:15:50.469490Z","shell.execute_reply.started":"2024-08-03T18:15:49.948668Z","shell.execute_reply":"2024-08-03T18:15:50.467618Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/bert/keras/bert_base_en/2/config.json\n/kaggle/input/bert/keras/bert_base_en/2/tokenizer.json\n/kaggle/input/bert/keras/bert_base_en/2/metadata.json\n/kaggle/input/bert/keras/bert_base_en/2/model.weights.h5\n/kaggle/input/bert/keras/bert_base_en/2/assets/tokenizer/vocabulary.txt\n/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n/kaggle/input/lmsys-chatbot-arena/train.csv\n/kaggle/input/lmsys-chatbot-arena/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set(font_scale=2)\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.metrics import log_loss\nfrom keras.models import Model\nfrom nltk.stem import PorterStemmer, SnowballStemmer\n\n\nimport keras\nimport tensorflow as tf\nfrom keras.utils import normalize, to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, TextVectorization, Softmax, BatchNormalization\nfrom keras.models import Sequential\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.preprocessing import sequence\nimport keras_tuner as kt\n\n# to avoid warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:15:52.655384Z","iopub.execute_input":"2024-08-03T18:15:52.655958Z","iopub.status.idle":"2024-08-03T18:15:58.701955Z","shell.execute_reply.started":"2024-08-03T18:15:52.655924Z","shell.execute_reply":"2024-08-03T18:15:58.700664Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"2024-08-03 18:15:54.565534: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-03 18:15:54.565618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-03 18:15:54.568360: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:15:58.704384Z","iopub.execute_input":"2024-08-03T18:15:58.705109Z","iopub.status.idle":"2024-08-03T18:15:58.710475Z","shell.execute_reply.started":"2024-08-03T18:15:58.705059Z","shell.execute_reply":"2024-08-03T18:15:58.708970Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Loading and exploring the train and test datasets:","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:15:58.712139Z","iopub.execute_input":"2024-08-03T18:15:58.712529Z","iopub.status.idle":"2024-08-03T18:16:01.569463Z","shell.execute_reply.started":"2024-08-03T18:15:58.712495Z","shell.execute_reply":"2024-08-03T18:16:01.568134Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.572229Z","iopub.execute_input":"2024-08-03T18:16:01.572634Z","iopub.status.idle":"2024-08-03T18:16:01.594248Z","shell.execute_reply.started":"2024-08-03T18:16:01.572599Z","shell.execute_reply":"2024-08-03T18:16:01.592742Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.595952Z","iopub.execute_input":"2024-08-03T18:16:01.596455Z","iopub.status.idle":"2024-08-03T18:16:01.612406Z","shell.execute_reply.started":"2024-08-03T18:16:01.596416Z","shell.execute_reply":"2024-08-03T18:16:01.610979Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.613953Z","iopub.execute_input":"2024-08-03T18:16:01.614441Z","iopub.status.idle":"2024-08-03T18:16:01.677396Z","shell.execute_reply.started":"2024-08-03T18:16:01.614403Z","shell.execute_reply":"2024-08-03T18:16:01.675875Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.678802Z","iopub.execute_input":"2024-08-03T18:16:01.679191Z","iopub.status.idle":"2024-08-03T18:16:01.712809Z","shell.execute_reply.started":"2024-08-03T18:16:01.679149Z","shell.execute_reply":"2024-08-03T18:16:01.711565Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"I'm interested to see what models are winning most often in the datasets:","metadata":{}},{"cell_type":"code","source":"winner_a = train[train['winner_model_a']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.714287Z","iopub.execute_input":"2024-08-03T18:16:01.714673Z","iopub.status.idle":"2024-08-03T18:16:01.727197Z","shell.execute_reply.started":"2024-08-03T18:16:01.714638Z","shell.execute_reply":"2024-08-03T18:16:01.725796Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"winner_b = train[train['winner_model_b']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.729041Z","iopub.execute_input":"2024-08-03T18:16:01.729657Z","iopub.status.idle":"2024-08-03T18:16:01.741333Z","shell.execute_reply.started":"2024-08-03T18:16:01.729618Z","shell.execute_reply":"2024-08-03T18:16:01.739973Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"winner_a['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.746281Z","iopub.execute_input":"2024-08-03T18:16:01.746899Z","iopub.status.idle":"2024-08-03T18:16:01.763250Z","shell.execute_reply.started":"2024-08-03T18:16:01.746851Z","shell.execute_reply":"2024-08-03T18:16:01.761766Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"model_a\ngpt-4-1106-preview          2019\ngpt-4-0613                  1280\ngpt-3.5-turbo-0613          1213\ngpt-4-0314                  1033\nclaude-2.1                   896\n                            ... \nchatglm2-6b                   35\nqwen1.5-7b-chat               29\nopenchat-3.5-0106             28\nqwen1.5-4b-chat               19\nmistral-7b-instruct-v0.2      15\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"winner_b['model_b'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.764659Z","iopub.execute_input":"2024-08-03T18:16:01.765109Z","iopub.status.idle":"2024-08-03T18:16:01.785589Z","shell.execute_reply.started":"2024-08-03T18:16:01.765074Z","shell.execute_reply":"2024-08-03T18:16:01.784182Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"model_b\ngpt-4-1106-preview          2054\ngpt-4-0613                  1170\ngpt-3.5-turbo-0613          1168\ngpt-4-0314                   960\nclaude-1                     880\n                            ... \nchatglm2-6b                   38\nopenchat-3.5-0106             35\nqwen1.5-7b-chat               22\nqwen1.5-4b-chat               16\nmistral-7b-instruct-v0.2      12\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The top 4 models that won most often as model a or as model b are:\n- gpt-4-1106-preview\n- gpt-4-0613\n- gpt-3.5-turbo-0613\n- gpt-4-0314","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Since the 'prompt', 'response_a', and 'response_b' features are text, they need to be cleaned and pre-processed before they are tokenized and vectorized.","metadata":{}},{"cell_type":"code","source":"# Need to make sure the relevant features are all in string format\n\ntrain['prompt'] = train['prompt'].astype(str)\ntrain['response_a'] = train['response_a'].astype(str)\ntrain['response_b'] = train['response_b'].astype(str)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.787169Z","iopub.execute_input":"2024-08-03T18:16:01.787615Z","iopub.status.idle":"2024-08-03T18:16:01.819881Z","shell.execute_reply.started":"2024-08-03T18:16:01.787543Z","shell.execute_reply":"2024-08-03T18:16:01.818223Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # getting the total vocab length before text cleaning/preprocessing\n# combined_text1 = train['prompt'] + ' ' + train['response_a'] + ' ' + train['response_b']\n# data1 = combined_text1.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.821569Z","iopub.execute_input":"2024-08-03T18:16:01.822024Z","iopub.status.idle":"2024-08-03T18:16:01.828847Z","shell.execute_reply.started":"2024-08-03T18:16:01.821988Z","shell.execute_reply":"2024-08-03T18:16:01.827578Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary1 = set(word for combined_text1 in data1 for word in combined_text1)\n# print(len(total_vocabulary1))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.830609Z","iopub.execute_input":"2024-08-03T18:16:01.831018Z","iopub.status.idle":"2024-08-03T18:16:01.843759Z","shell.execute_reply.started":"2024-08-03T18:16:01.830984Z","shell.execute_reply":"2024-08-03T18:16:01.842188Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary1)))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.845566Z","iopub.execute_input":"2024-08-03T18:16:01.846031Z","iopub.status.idle":"2024-08-03T18:16:01.858695Z","shell.execute_reply.started":"2024-08-03T18:16:01.845995Z","shell.execute_reply":"2024-08-03T18:16:01.857266Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Before cleaning and preprocessing the text features, the dataset contains 942,074 unique words.","metadata":{}},{"cell_type":"code","source":"# Creating a function to perform cleaning steps at once (Removes numbers and unnecessary characters, makes all letters lowercase, removes stopwords)\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\nno_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\nno_nums = re.compile('[\\d-]')\n\ndef clean_text(text):\n    text = no_nums.sub('', text)\n    text = no_bad_chars.sub(' ', text)\n    text = text.lower()\n    text = stemmer.stem(text)\n    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n\n    return text\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.860242Z","iopub.execute_input":"2024-08-03T18:16:01.860680Z","iopub.status.idle":"2024-08-03T18:16:01.886396Z","shell.execute_reply.started":"2024-08-03T18:16:01.860580Z","shell.execute_reply":"2024-08-03T18:16:01.884977Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#Applying text cleaning function to text columns\ntrain_cleaned = train.copy()\ntrain_cleaned['prompt'] = (train['prompt']).apply(clean_text)\ntrain_cleaned['response_a'] = (train['response_a']).apply(clean_text)\ntrain_cleaned['response_b'] = (train['response_b']).apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:16:01.888182Z","iopub.execute_input":"2024-08-03T18:16:01.889063Z","iopub.status.idle":"2024-08-03T18:18:11.038137Z","shell.execute_reply.started":"2024-08-03T18:16:01.889013Z","shell.execute_reply":"2024-08-03T18:18:11.036891Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# train_cleaned['winner_model_a'] = train['winner_model_a']\n# train_cleaned['winner_model_b'] = train['winner_model_b']\n# train_cleaned['winner_tie'] = train['winner_tie']","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.039868Z","iopub.execute_input":"2024-08-03T18:18:11.040263Z","iopub.status.idle":"2024-08-03T18:18:11.045803Z","shell.execute_reply.started":"2024-08-03T18:18:11.040229Z","shell.execute_reply":"2024-08-03T18:18:11.044352Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.prompt.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.047822Z","iopub.execute_input":"2024-08-03T18:18:11.048358Z","iopub.status.idle":"2024-08-03T18:18:11.116058Z","shell.execute_reply.started":"2024-08-03T18:18:11.048314Z","shell.execute_reply":"2024-08-03T18:18:11.114755Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"252"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_a.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.117451Z","iopub.execute_input":"2024-08-03T18:18:11.117804Z","iopub.status.idle":"2024-08-03T18:18:11.180887Z","shell.execute_reply.started":"2024-08-03T18:18:11.117774Z","shell.execute_reply":"2024-08-03T18:18:11.179495Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_b.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.182420Z","iopub.execute_input":"2024-08-03T18:18:11.182961Z","iopub.status.idle":"2024-08-03T18:18:11.248253Z","shell.execute_reply.started":"2024-08-03T18:18:11.182924Z","shell.execute_reply":"2024-08-03T18:18:11.247198Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"270"},"metadata":{}}]},{"cell_type":"code","source":"train_cleaned2 = train_cleaned[(train_cleaned.prompt.astype(str).str.len()>0) & (train_cleaned.response_a.astype(str).str.len()>0)& (train_cleaned.response_b.astype(str).str.len()>0)]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.249550Z","iopub.execute_input":"2024-08-03T18:18:11.249914Z","iopub.status.idle":"2024-08-03T18:18:11.420571Z","shell.execute_reply.started":"2024-08-03T18:18:11.249875Z","shell.execute_reply":"2024-08-03T18:18:11.419323Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_cleaned2.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.426357Z","iopub.execute_input":"2024-08-03T18:18:11.426806Z","iopub.status.idle":"2024-08-03T18:18:11.481203Z","shell.execute_reply.started":"2024-08-03T18:18:11.426770Z","shell.execute_reply":"2024-08-03T18:18:11.479712Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 56800 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              56800 non-null  int64 \n 1   model_a         56800 non-null  object\n 2   model_b         56800 non-null  object\n 3   prompt          56800 non-null  object\n 4   response_a      56800 non-null  object\n 5   response_b      56800 non-null  object\n 6   winner_model_a  56800 non-null  int64 \n 7   winner_model_b  56800 non-null  int64 \n 8   winner_tie      56800 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 4.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_cleaned.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.482864Z","iopub.execute_input":"2024-08-03T18:18:11.483300Z","iopub.status.idle":"2024-08-03T18:18:11.517944Z","shell.execute_reply.started":"2024-08-03T18:18:11.483266Z","shell.execute_reply":"2024-08-03T18:18:11.516518Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # getting the total vocab length for the trainset after cleaning/preprocessing and removing empty strings\n# combined_text2 = train_cleaned2['prompt'] + ' ' + train_cleaned2['response_a'] + ' ' + train_cleaned2['response_b']\n# data2 = combined_text2.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.519702Z","iopub.execute_input":"2024-08-03T18:18:11.520105Z","iopub.status.idle":"2024-08-03T18:18:11.525114Z","shell.execute_reply.started":"2024-08-03T18:18:11.520073Z","shell.execute_reply":"2024-08-03T18:18:11.523939Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary2 = set(word for combined_text2 in data2 for word in combined_text2)\n# print(len(total_vocabulary2))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.526574Z","iopub.execute_input":"2024-08-03T18:18:11.526908Z","iopub.status.idle":"2024-08-03T18:18:11.540239Z","shell.execute_reply.started":"2024-08-03T18:18:11.526880Z","shell.execute_reply":"2024-08-03T18:18:11.538915Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary2)))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.542241Z","iopub.execute_input":"2024-08-03T18:18:11.542644Z","iopub.status.idle":"2024-08-03T18:18:11.552522Z","shell.execute_reply.started":"2024-08-03T18:18:11.542610Z","shell.execute_reply":"2024-08-03T18:18:11.551103Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"<em>After</em> cleaning and preprocessing the text features, the dataset contains 410,804 unique words. This is a huge improvement.","metadata":{}},{"cell_type":"markdown","source":"Removing any unnecessary features:","metadata":{}},{"cell_type":"code","source":"# The features 'model_a','model_b' are not in the test dataset, so I won't use these for modeling\n# Also, the ID feature won't add anything useful to our model so it's best to remove it so it doesn't confuse by adding extra info\n\ntrain_cleaned2.pop('model_a')\n\ntrain_cleaned2.pop('model_b')\n\ntrain_cleaned2.pop('id')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.553986Z","iopub.execute_input":"2024-08-03T18:18:11.554721Z","iopub.status.idle":"2024-08-03T18:18:11.576354Z","shell.execute_reply.started":"2024-08-03T18:18:11.554682Z","shell.execute_reply":"2024-08-03T18:18:11.575027Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0             30192\n1             53567\n2             65089\n3             96401\n4            198779\n            ...    \n57472    4294656694\n57473    4294692063\n57474    4294710549\n57475    4294899228\n57476    4294947231\nName: id, Length: 56800, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Train-test splitting the data:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_, test_ = train_test_split(train_cleaned2, test_size=0.2, random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.577641Z","iopub.execute_input":"2024-08-03T18:18:11.577980Z","iopub.status.idle":"2024-08-03T18:18:11.608700Z","shell.execute_reply.started":"2024-08-03T18:18:11.577954Z","shell.execute_reply":"2024-08-03T18:18:11.607312Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"We need to create a target that includes all three of the outcomes we are trying to predict (winner_model_a, winner_model_b, winner_tie):","metadata":{}},{"cell_type":"code","source":"def target(data):\n    y1 = data.pop('winner_model_a')\n    y1 = np.array(y1)\n    y2 = data.pop('winner_model_b')\n    y2 = np.array(y2)\n    y3 = data.pop('winner_tie')\n    y3 = np.array(y3)\n    return y1, y2, y3\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.610624Z","iopub.execute_input":"2024-08-03T18:18:11.610997Z","iopub.status.idle":"2024-08-03T18:18:11.617085Z","shell.execute_reply.started":"2024-08-03T18:18:11.610966Z","shell.execute_reply":"2024-08-03T18:18:11.615798Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#format the outputs for both train and test sets\ntarget_train = target(train_)\ntarget_test = target(test_)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.618845Z","iopub.execute_input":"2024-08-03T18:18:11.619343Z","iopub.status.idle":"2024-08-03T18:18:11.633624Z","shell.execute_reply.started":"2024-08-03T18:18:11.619301Z","shell.execute_reply":"2024-08-03T18:18:11.632048Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"target_train= np.transpose(target_train)\ntarget_test= np.transpose(target_test)\ntarget_train","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.635626Z","iopub.execute_input":"2024-08-03T18:18:11.636184Z","iopub.status.idle":"2024-08-03T18:18:11.647849Z","shell.execute_reply.started":"2024-08-03T18:18:11.636139Z","shell.execute_reply":"2024-08-03T18:18:11.646675Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([[1, 0, 0],\n       [0, 0, 1],\n       [1, 0, 0],\n       ...,\n       [0, 1, 0],\n       [0, 1, 0],\n       [0, 1, 0]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Each of the input features need to be tokenized and vectorized, so that a model can interpret them:","metadata":{}},{"cell_type":"code","source":"print(train_.prompt.str.len().max())\nprint(train_.response_a.str.len().max())\nprint(train_.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.649338Z","iopub.execute_input":"2024-08-03T18:18:11.649682Z","iopub.status.idle":"2024-08-03T18:18:11.787080Z","shell.execute_reply.started":"2024-08-03T18:18:11.649654Z","shell.execute_reply":"2024-08-03T18:18:11.785815Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"24848\n35411\n34440\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_.prompt.str.len().max())\nprint(test_.response_a.str.len().max())\nprint(test_.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.788512Z","iopub.execute_input":"2024-08-03T18:18:11.788847Z","iopub.status.idle":"2024-08-03T18:18:11.829890Z","shell.execute_reply.started":"2024-08-03T18:18:11.788819Z","shell.execute_reply":"2024-08-03T18:18:11.828480Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"16941\n22387\n41202\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=410804)\n\ntokenizer.fit_on_texts(list(train_))\ntokenized_tr = tokenizer.texts_to_sequences(train_)\n\n# tokenizer.fit_on_texts(list(test_))\ntokenized_te = tokenizer.texts_to_sequences(test_)\n ","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.831351Z","iopub.execute_input":"2024-08-03T18:18:11.831689Z","iopub.status.idle":"2024-08-03T18:18:11.846502Z","shell.execute_reply.started":"2024-08-03T18:18:11.831660Z","shell.execute_reply":"2024-08-03T18:18:11.845079Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Next, to make sure all the tokenized sequences are the same length, I'm going to pad them all to the length of the <strong>longest sequence</strong>. Any sequences shorter than that will be truncated to meet the size requirement.","metadata":{}},{"cell_type":"code","source":"max_seq_len = 20000\nX_train = sequence.pad_sequences(tokenized_tr, padding = 'post', maxlen=max_seq_len, truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.847895Z","iopub.execute_input":"2024-08-03T18:18:11.848304Z","iopub.status.idle":"2024-08-03T18:18:11.861897Z","shell.execute_reply.started":"2024-08-03T18:18:11.848269Z","shell.execute_reply":"2024-08-03T18:18:11.860549Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"np.shape(target_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.863502Z","iopub.execute_input":"2024-08-03T18:18:11.863910Z","iopub.status.idle":"2024-08-03T18:18:11.878213Z","shell.execute_reply.started":"2024-08-03T18:18:11.863874Z","shell.execute_reply":"2024-08-03T18:18:11.876921Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(45440, 3)"},"metadata":{}}]},{"cell_type":"code","source":"max_seq_len = 20000\nX_test = sequence.pad_sequences(tokenized_te, padding = 'post', maxlen=max_seq_len, truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.879994Z","iopub.execute_input":"2024-08-03T18:18:11.880408Z","iopub.status.idle":"2024-08-03T18:18:11.891492Z","shell.execute_reply.started":"2024-08-03T18:18:11.880374Z","shell.execute_reply":"2024-08-03T18:18:11.889815Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"X_train = np.transpose(X_train)\nX_test = np.transpose(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.893350Z","iopub.execute_input":"2024-08-03T18:18:11.893955Z","iopub.status.idle":"2024-08-03T18:18:11.904782Z","shell.execute_reply.started":"2024-08-03T18:18:11.893916Z","shell.execute_reply":"2024-08-03T18:18:11.903390Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# # demonstrate data normalization with sklearn\n# from sklearn.preprocessing import MinMaxScaler\n# # load data\n# data1 = X_train\n# data2 = X_test\n# # create scaler\n# scaler = MinMaxScaler()\n# # fit and transform in one step\n# normalized_train = scaler.fit_transform(data1)\n# normalized_test = scaler.fit_transform(data2)\n\n# # inverse transform\n# inverse_train = scaler.inverse_transform(normalized_train)\n# inverse_test = scaler.inverse_transform(normalized_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:44:22.658509Z","iopub.execute_input":"2024-07-29T20:44:22.659011Z","iopub.status.idle":"2024-07-29T20:44:22.668748Z","shell.execute_reply.started":"2024-07-29T20:44:22.658958Z","shell.execute_reply":"2024-07-29T20:44:22.667449Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# load data\ndata1 = X_train\ndata2 = X_test\n# create scaler\nscaler = StandardScaler()\n# fit and transform in one step\nstandardized_train = scaler.fit_transform(data1)\nstandardized_test = scaler.fit_transform(data2)\n# inverse transform\ninverse_train = scaler.inverse_transform(standardized_train)\ninverse_test = scaler.inverse_transform(standardized_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:18:11.906510Z","iopub.execute_input":"2024-08-03T18:18:11.907146Z","iopub.status.idle":"2024-08-03T18:18:11.923719Z","shell.execute_reply.started":"2024-08-03T18:18:11.907069Z","shell.execute_reply":"2024-08-03T18:18:11.922317Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# vocab_size = 410804\n# max_seq_len = 2000\n\n# tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\n# tokenizer.fit_on_texts(train_)\n\n# sequences_train = tokenizer.texts_to_sequences(train_)\n# sequences_test = tokenizer.texts_to_sequences(test_)\n\n# padded_train = pad_sequences(sequences_train, maxlen=max_seq_len)\n# padded_test = pad_sequences(sequences_test, maxlen=max_seq_len)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:53:49.387296Z","iopub.execute_input":"2024-07-29T20:53:49.387788Z","iopub.status.idle":"2024-07-29T20:53:49.397133Z","shell.execute_reply.started":"2024-07-29T20:53:49.387736Z","shell.execute_reply":"2024-07-29T20:53:49.395563Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# padded_train = np.transpose(padded_train)\n# padded_test = np.transpose(padded_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:53:50.804054Z","iopub.execute_input":"2024-07-29T20:53:50.804501Z","iopub.status.idle":"2024-07-29T20:53:50.810565Z","shell.execute_reply.started":"2024-07-29T20:53:50.804467Z","shell.execute_reply":"2024-07-29T20:53:50.809157Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"# from keras.models import Sequential\n# from keras.layers import Dense, Activation\n# #Configure the model\n# model3 = Sequential()\n# model3.add(Dense(512, input_shape =(3,)))\n# model3.add(Activation('relu'))\n# model3.add(Dense(3))\n# model3.add(Activation('softmax'))\n    \n# #     layers.Embedding(input_dim = 3, output_dim = 150,  mask_zero=True), \n# # #                                     tf.keras.layers.Dropout(0.6),\n# # #                                     tf.keras.layers.LSTM(64, activation=tf.nn.relu), \n# #     layers.LSTM(3, activation=tf.nn.relu),\n# #     layers.Dense(3, activation=tf.nn.softmax)])\n# model3.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n# print(model3.metrics_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:14:32.777171Z","iopub.execute_input":"2024-08-03T18:14:32.777659Z","iopub.status.idle":"2024-08-03T18:14:32.785441Z","shell.execute_reply.started":"2024-08-03T18:14:32.777613Z","shell.execute_reply":"2024-08-03T18:14:32.783931Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:00:52.746705Z","iopub.execute_input":"2024-07-29T21:00:52.747200Z","iopub.status.idle":"2024-07-29T21:00:52.752838Z","shell.execute_reply.started":"2024-07-29T21:00:52.747156Z","shell.execute_reply":"2024-07-29T21:00:52.751435Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                      \n                                  patience=5,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n ]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:26.323983Z","iopub.execute_input":"2024-08-03T18:26:26.324851Z","iopub.status.idle":"2024-08-03T18:26:26.331235Z","shell.execute_reply.started":"2024-08-03T18:26:26.324806Z","shell.execute_reply":"2024-08-03T18:26:26.329640Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# model3.fit(padded_train,\n#            target_train,\n#     epochs=10,\n#     batch_size=64,\n#     validation_split=0.2,\n#     callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:14:35.845282Z","iopub.execute_input":"2024-08-03T18:14:35.845712Z","iopub.status.idle":"2024-08-03T18:14:35.851593Z","shell.execute_reply.started":"2024-08-03T18:14:35.845680Z","shell.execute_reply":"2024-08-03T18:14:35.849988Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# predictions3 = model3.predict(padded_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:14:37.302309Z","iopub.execute_input":"2024-08-03T18:14:37.302704Z","iopub.status.idle":"2024-08-03T18:14:37.308496Z","shell.execute_reply.started":"2024-08-03T18:14:37.302673Z","shell.execute_reply":"2024-08-03T18:14:37.307066Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# predictions3[:10]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:14:40.216844Z","iopub.execute_input":"2024-08-03T18:14:40.217251Z","iopub.status.idle":"2024-08-03T18:14:40.222789Z","shell.execute_reply.started":"2024-08-03T18:14:40.217219Z","shell.execute_reply":"2024-08-03T18:14:40.221040Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#sequential model\n\n\ndef get_model():\n    model = Sequential()\n    model.add(Input(shape=(3,)))\n#     model3.add(Dense(512, input_shape =(20000,)))\n    model.add(\n        Embedding(input_dim=20000,\n                  output_dim=300))\n#     model.add(\n#         Embedding(input_dim=2000,\n#                   output_dim=100))\n#     model.add(\n#         Embedding(input_dim=2000,\n#                   output_dim=100))\n    \n    \n    model.add(Dropout(0.6))\n    model.add(LSTM(512,return_sequences=True))\n    model.add(LSTM(256))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Dense(128,activation='leaky_relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Dense(64,activation='leaky_relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Dense(32,activation='leaky_relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(layers.Flatten())\n    \n    model.add(Dense(3,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:13.121725Z","iopub.execute_input":"2024-08-03T18:26:13.122355Z","iopub.status.idle":"2024-08-03T18:26:13.135414Z","shell.execute_reply.started":"2024-08-03T18:26:13.122314Z","shell.execute_reply":"2024-08-03T18:26:13.133896Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model_seq = get_model()\nmodel_seq.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:14.941846Z","iopub.execute_input":"2024-08-03T18:26:14.942320Z","iopub.status.idle":"2024-08-03T18:26:15.633372Z","shell.execute_reply.started":"2024-08-03T18:26:14.942283Z","shell.execute_reply":"2024-08-03T18:26:15.632208Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │     \u001b[38;5;34m6,000,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m1,665,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,665,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,497,731\u001b[0m (32.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,497,731</span> (32.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,496,771\u001b[0m (32.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,496,771</span> (32.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_seq.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=[keras.metrics.CategoricalAccuracy])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:17.295094Z","iopub.execute_input":"2024-08-03T18:26:17.295569Z","iopub.status.idle":"2024-08-03T18:26:17.316387Z","shell.execute_reply.started":"2024-08-03T18:26:17.295525Z","shell.execute_reply":"2024-08-03T18:26:17.314625Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model_seq.fit(\n    inverse_train,\n    target_train,\n    validation_split = 0.1,\n    callbacks=callbacks,\n    batch_size=64,\n    shuffle=True,\n    epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:26:28.352837Z","iopub.execute_input":"2024-08-03T18:26:28.353293Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m184/282\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - categorical_accuracy: 0.3327 - loss: 1.4793","output_type":"stream"}]},{"cell_type":"code","source":"# keras.utils.plot_model(model_seq, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_seq = model_seq.predict(inverse_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:01:51.075345Z","iopub.execute_input":"2024-07-29T21:01:51.075787Z","iopub.status.idle":"2024-07-29T21:01:51.753452Z","shell.execute_reply.started":"2024-07-29T21:01:51.075752Z","shell.execute_reply":"2024-07-29T21:01:51.752004Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_seq","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:01:51.756136Z","iopub.execute_input":"2024-07-29T21:01:51.756620Z","iopub.status.idle":"2024-07-29T21:01:51.764970Z","shell.execute_reply.started":"2024-07-29T21:01:51.756575Z","shell.execute_reply":"2024-07-29T21:01:51.763695Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"array([[0.3422091 , 0.36923832, 0.28855258],\n       [0.3422091 , 0.36923832, 0.28855258],\n       [0.3422091 , 0.36923832, 0.28855258],\n       ...,\n       [0.3422091 , 0.36923832, 0.28855258],\n       [0.34654814, 0.3667524 , 0.28669944],\n       [0.34566632, 0.3651882 , 0.28914532]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# #functional model - most shallow\n# input_ = Input(shape=(3,))\n\n# # Embed each word in the text features into a ???-dimensional vector\n\n# embedding_size = 100\n\n# emb1 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input1 = emb1(input_)\n\n\n# # embs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n# # embs = keras.layers.GlobalAveragePooling1D()(embs)\n\n# dropout = layers.Dropout(0.8)(emb_input1)\n\n# lstm = layers.LSTM(64, activation='leaky_relu')(dropout)\n\n\n# dense3 = layers.Dense(32, activation = 'leaky_relu')(lstm)\n# batch_norm3 = BatchNormalization()(dense3)\n# dropout3 = layers.Dropout(0.8)(batch_norm3)\n\n# out = layers.Dense(3, activation = 'softmax')(dropout3)\n\n\n# # Instantiate an end-to-end model predicting both priority and department\n# model_func1 = keras.Model(input_,out)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:47:28.659432Z","iopub.execute_input":"2024-07-29T20:47:28.659843Z","iopub.status.idle":"2024-07-29T20:47:28.747240Z","shell.execute_reply.started":"2024-07-29T20:47:28.659814Z","shell.execute_reply":"2024-07-29T20:47:28.745715Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# #functional model - second most shallow\n# input_ = Input(shape=(3,))\n\n# # Embed each word in the text features into a ???-dimensional vector\n\n# embedding_size = 100\n\n# emb1 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input1 = emb1(input_)\n\n# emb2 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input2 = emb2(input_)\n\n# emb3 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input3 = emb3(input_)\n\n# embs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n\n# # embs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n# # embs = keras.layers.GlobalAveragePooling1D()(embs)\n\n# dropout = layers.Dropout(0.8)(embs)\n\n# lstm = layers.LSTM(64, activation='leaky_relu')(dropout)\n\n\n# dense3 = layers.Dense(32, activation = 'leaky_relu')(lstm)\n# batch_norm3 = BatchNormalization()(dense3)\n# dropout3 = layers.Dropout(0.8)(batch_norm3)\n\n# out = layers.Dense(3, activation = 'softmax')(dropout3)\n\n\n# # Instantiate an end-to-end model predicting both priority and department\n# model_func2 = keras.Model(input_,out)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:47:29.160669Z","iopub.execute_input":"2024-07-29T20:47:29.161069Z","iopub.status.idle":"2024-07-29T20:47:29.169018Z","shell.execute_reply.started":"2024-07-29T20:47:29.161038Z","shell.execute_reply":"2024-07-29T20:47:29.167531Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#functional model - deepest\ninput_ = Input(shape=(3,))\n\n# Embed each word in the text features into a ???-dimensional vector\n\nembedding_size = 100\n\nemb1 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\nemb_input1 = emb1(input_)\n\nemb2 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\nemb_input2 = emb2(input_)\n\nemb3 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\nemb_input3 = emb3(input_)\n\nembs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n# embs = keras.layers.GlobalAveragePooling1D()(embs)\n\ndropout = layers.Dropout(0.8)(emb_input1)\n\nlstm = layers.LSTM(128, activation='leaky_relu')(dropout)\n\n\n\ndense1 = layers.Dense(64, activation = 'leaky_relu')(lstm)\nbatch_norm1 = BatchNormalization()(dense1)\ndropout1 = layers.Dropout(0.8)(batch_norm1)\ndense2 = layers.Dense(32, activation = 'leaky_relu')(dropout1)\nbatch_norm2 = BatchNormalization()(dense2)\ndropout2 = layers.Dropout(0.8)(batch_norm2)\ndense3 = layers.Dense(16, activation = 'leaky_relu')(lstm)\nbatch_norm3 = BatchNormalization()(dense3)\ndropout3 = layers.Dropout(0.8)(batch_norm3)\n\nout = layers.Dense(3, activation = 'softmax')(dropout3)\n\n\n# Instantiate an end-to-end model predicting both priority and department\nmodel_func = keras.Model(input_,out)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:04.250045Z","iopub.execute_input":"2024-07-29T21:03:04.251795Z","iopub.status.idle":"2024-07-29T21:03:04.397691Z","shell.execute_reply.started":"2024-07-29T21:03:04.251739Z","shell.execute_reply":"2024-07-29T21:03:04.396480Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# model_func1.compile(\n#     loss='categorical_crossentropy', \n#     optimizer=keras.optimizers.Adam(learning_rate=0.001), \n#     metrics=[keras.metrics.CategoricalAccuracy])\n# # keras.metrics.CategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:05.785888Z","iopub.execute_input":"2024-07-29T21:03:05.786348Z","iopub.status.idle":"2024-07-29T21:03:05.798765Z","shell.execute_reply.started":"2024-07-29T21:03:05.786310Z","shell.execute_reply":"2024-07-29T21:03:05.797300Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# model_func2.compile(\n#     loss='categorical_crossentropy', \n#     optimizer=keras.optimizers.Adam(learning_rate=0.001), \n#     metrics=[keras.metrics.CategoricalAccuracy])\n# # keras.metrics.CategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:06.090542Z","iopub.execute_input":"2024-07-29T21:03:06.090954Z","iopub.status.idle":"2024-07-29T21:03:06.096852Z","shell.execute_reply.started":"2024-07-29T21:03:06.090922Z","shell.execute_reply":"2024-07-29T21:03:06.095453Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"model_func.compile(\n    loss='categorical_crossentropy', \n    optimizer=keras.optimizers.Adam(learning_rate=0.001), \n    metrics=[keras.metrics.CategoricalAccuracy])\n# keras.metrics.CategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:06.445286Z","iopub.execute_input":"2024-07-29T21:03:06.446414Z","iopub.status.idle":"2024-07-29T21:03:06.457142Z","shell.execute_reply.started":"2024-07-29T21:03:06.446373Z","shell.execute_reply":"2024-07-29T21:03:06.455710Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# keras.utils.plot_model(model_func, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:07.951842Z","iopub.execute_input":"2024-07-29T21:03:07.952330Z","iopub.status.idle":"2024-07-29T21:03:07.957367Z","shell.execute_reply.started":"2024-07-29T21:03:07.952292Z","shell.execute_reply":"2024-07-29T21:03:07.956071Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# model_func1.fit(\n#     padded_train,\n#     target_train,\n#     validation_split = 0.33,\n# #     callbacks=callbacks,\n#     batch_size=16,\n#     shuffle=True,\n#     epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:08.503345Z","iopub.execute_input":"2024-07-29T21:03:08.503773Z","iopub.status.idle":"2024-07-29T21:03:08.509257Z","shell.execute_reply.started":"2024-07-29T21:03:08.503741Z","shell.execute_reply":"2024-07-29T21:03:08.507907Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# model_func2.fit(\n#     inverse_train,\n#     target_train,\n#     validation_split = 0.33,\n# #     callbacks=callbacks,\n#     batch_size=16,\n#     shuffle=True,\n#     epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:09.398901Z","iopub.execute_input":"2024-07-29T21:03:09.399925Z","iopub.status.idle":"2024-07-29T21:03:09.405277Z","shell.execute_reply.started":"2024-07-29T21:03:09.399884Z","shell.execute_reply":"2024-07-29T21:03:09.403860Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"model_func.fit(\n    padded_train,\n    target_train,\n    validation_split = 0.1,\n#     callbacks=callbacks,\n    batch_size=16,\n    shuffle=True,\n    epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:03:10.157398Z","iopub.execute_input":"2024-07-29T21:03:10.157826Z","iopub.status.idle":"2024-07-29T21:03:23.400520Z","shell.execute_reply.started":"2024-07-29T21:03:10.157795Z","shell.execute_reply":"2024-07-29T21:03:23.399197Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - categorical_accuracy: 0.3393 - loss: 1.0978 - val_categorical_accuracy: 0.4150 - val_loss: 1.0892\nEpoch 2/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - categorical_accuracy: 0.3457 - loss: 1.0982 - val_categorical_accuracy: 0.3600 - val_loss: 1.0891\nEpoch 3/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - categorical_accuracy: 0.3422 - loss: 1.1002 - val_categorical_accuracy: 0.3600 - val_loss: 1.0875\nEpoch 4/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - categorical_accuracy: 0.3723 - loss: 1.0981 - val_categorical_accuracy: 0.3550 - val_loss: 1.0896\nEpoch 5/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - categorical_accuracy: 0.3282 - loss: 1.0999 - val_categorical_accuracy: 0.4150 - val_loss: 1.0877\nEpoch 6/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - categorical_accuracy: 0.3436 - loss: 1.0980 - val_categorical_accuracy: 0.4250 - val_loss: 1.0848\nEpoch 7/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - categorical_accuracy: 0.3466 - loss: 1.0969 - val_categorical_accuracy: 0.4250 - val_loss: 1.0827\nEpoch 8/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - categorical_accuracy: 0.3349 - loss: 1.0975 - val_categorical_accuracy: 0.4250 - val_loss: 1.0776\nEpoch 9/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - categorical_accuracy: 0.3453 - loss: 1.0993 - val_categorical_accuracy: 0.3550 - val_loss: 1.0899\nEpoch 10/10\n\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - categorical_accuracy: 0.3604 - loss: 1.0962 - val_categorical_accuracy: 0.3600 - val_loss: 1.0801\n","output_type":"stream"},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c9f601dae90>"},"metadata":{}}]},{"cell_type":"code","source":"func_preds = model_func.predict(padded_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:49:18.502396Z","iopub.execute_input":"2024-07-29T20:49:18.502842Z","iopub.status.idle":"2024-07-29T20:49:19.374250Z","shell.execute_reply.started":"2024-07-29T20:49:18.502806Z","shell.execute_reply":"2024-07-29T20:49:19.372820Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"func_preds","metadata":{"execution":{"iopub.status.busy":"2024-07-29T20:49:19.377145Z","iopub.execute_input":"2024-07-29T20:49:19.377574Z","iopub.status.idle":"2024-07-29T20:49:19.387181Z","shell.execute_reply.started":"2024-07-29T20:49:19.377540Z","shell.execute_reply":"2024-07-29T20:49:19.385709Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"array([[0.33542573, 0.3698071 , 0.29476723],\n       [0.33542573, 0.3698071 , 0.29476723],\n       [0.33542573, 0.3698071 , 0.29476723],\n       ...,\n       [0.33542573, 0.3698071 , 0.29476723],\n       [0.34058318, 0.37910753, 0.2803093 ],\n       [0.37394482, 0.3428126 , 0.28324255]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Tuning","metadata":{}},{"cell_type":"code","source":"vocab_size = 410804\n\ndef model_builder(hp):\n    input_ = Input(shape=(3,))\n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n    \n    em =  Embedding(input_dim=vocab_size,output_dim=hp_vector_size, mask_zero=True)\n    emb_input = emb(input_)\n    \n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n    dropout = Dropout(hp_dropout_rate)(emb_input)\n    \n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    lstm = LSTM(hp_lstm_units1,return_sequences=True)(dropout)\n    \n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=16, \n                            max_value=512, \n                            step=64)\n    lstm = LSTM(hp_lstm_units2)(dropout)\n    \n    out = Dense(3,activation='softmax')(lstm)\n    \n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    model = keras.Model(input_,out)\n    \n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 400000\n\ndef model_builder(hp):\n    model = Sequential()\n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n    model.add(\n        Embedding(input_dim=vocab_size,\n                  output_dim=150\n#                   input_length=max_seq_len\n                 ))\n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n    model.add(Dropout(hp_dropout_rate))\n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    model.add(LSTM(hp_lstm_units1,return_sequences=True))\n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=16, \n                            max_value=512, \n                            step=64)\n    model.add(LSTM(hp_lstm_units2))\n    model.add(Dense(3,activation='softmax'))\n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntuner1 = kt.Hyperband(model_builder,\n                     objective=kt.Objective(\"val_loss\", direction=\"min\"),\n                     max_epochs=5,\n                     factor=2\n                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntuner1.search(X_train, \n             target_train, \n             epochs=1, \n             validation_split=0.2, \n             callbacks=[stop_early]\n             )\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner1.get_best_hyperparameters(num_trials=1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\nmodel_best_hp = tuner1.hypermodel.build(best_hps)\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor='val_loss',\n                                  mode='min',\n                                  patience=5,\n                                  verbose=1,\n                                  restore_best_weights=True)  \n]\nhistory = model_best_hp.fit(X_train, \n                            target_train, \n                            epochs=10,\n                            callbacks=callbacks,\n                            validation_split=0.2)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nmodel_best_hp.save('./model_multiclass_tuned.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restore model\nloaded_model = tf.keras.models.load_model('./model_multiclass_tuned.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run predict with restored model\npredictions = loaded_model.predict(X_test)\n# winner_model_a = predictions[0]\n# winner_model_b = predictions[1]\n# winner_tie = predictions[2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating predictions for the test dataframe:","metadata":{}},{"cell_type":"code","source":"test.head( )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}