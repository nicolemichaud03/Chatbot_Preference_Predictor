{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Competition Notebook:\"LMSYS - Chatbot Arena Human Preference Predictions\"","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am conducting data exploration, analysis, and modeling in order to generate predictions for which Chatbot model will be preferred for a given prompt.","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-07T16:58:48.475158Z","iopub.execute_input":"2024-05-07T16:58:48.475576Z","iopub.status.idle":"2024-05-07T16:58:49.015615Z","shell.execute_reply.started":"2024-05-07T16:58:48.475541Z","shell.execute_reply":"2024-05-07T16:58:49.013889Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n/kaggle/input/lmsys-chatbot-arena/train.csv\n/kaggle/input/lmsys-chatbot-arena/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set(font_scale=2)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.metrics import precision_score, accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, auc, ConfusionMatrixDisplay\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import RegexpTokenizer, word_tokenize\nfrom sklearn.metrics import log_loss\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom nltk import FreqDist\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.multioutput import MultiOutputClassifier","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:23:13.956606Z","iopub.execute_input":"2024-05-07T17:23:13.957044Z","iopub.status.idle":"2024-05-07T17:23:13.977926Z","shell.execute_reply.started":"2024-05-07T17:23:13.957009Z","shell.execute_reply":"2024-05-07T17:23:13.976604Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Loading the train and test datasets:","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:51.229803Z","iopub.execute_input":"2024-05-07T16:58:51.230250Z","iopub.status.idle":"2024-05-07T16:58:55.314304Z","shell.execute_reply.started":"2024-05-07T16:58:51.230208Z","shell.execute_reply":"2024-05-07T16:58:55.313397Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.315612Z","iopub.execute_input":"2024-05-07T16:58:55.316423Z","iopub.status.idle":"2024-05-07T16:58:55.343435Z","shell.execute_reply.started":"2024-05-07T16:58:55.316387Z","shell.execute_reply":"2024-05-07T16:58:55.342102Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.346797Z","iopub.execute_input":"2024-05-07T16:58:55.347272Z","iopub.status.idle":"2024-05-07T16:58:55.358908Z","shell.execute_reply.started":"2024-05-07T16:58:55.347230Z","shell.execute_reply":"2024-05-07T16:58:55.357705Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.360792Z","iopub.execute_input":"2024-05-07T16:58:55.361550Z","iopub.status.idle":"2024-05-07T16:58:55.432929Z","shell.execute_reply.started":"2024-05-07T16:58:55.361507Z","shell.execute_reply":"2024-05-07T16:58:55.431602Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.434599Z","iopub.execute_input":"2024-05-07T16:58:55.435418Z","iopub.status.idle":"2024-05-07T16:58:55.469608Z","shell.execute_reply.started":"2024-05-07T16:58:55.435383Z","shell.execute_reply":"2024-05-07T16:58:55.468308Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.471258Z","iopub.execute_input":"2024-05-07T16:58:55.471710Z","iopub.status.idle":"2024-05-07T16:58:55.489719Z","shell.execute_reply.started":"2024-05-07T16:58:55.471677Z","shell.execute_reply":"2024-05-07T16:58:55.488489Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"model_a\ngpt-4-1106-preview          3678\ngpt-3.5-turbo-0613          3553\ngpt-4-0613                  3099\nclaude-2.1                  2859\ngpt-4-0314                  2087\n                            ... \nfalcon-180b-chat             145\nopenchat-3.5-0106            108\nqwen1.5-7b-chat              106\nqwen1.5-4b-chat              100\nmistral-7b-instruct-v0.2      54\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train['model_b'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:58:55.491147Z","iopub.execute_input":"2024-05-07T16:58:55.491521Z","iopub.status.idle":"2024-05-07T16:58:55.511087Z","shell.execute_reply.started":"2024-05-07T16:58:55.491486Z","shell.execute_reply":"2024-05-07T16:58:55.509718Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"model_b\ngpt-4-1106-preview          3709\ngpt-3.5-turbo-0613          3530\ngpt-4-0613                  3066\nclaude-2.1                  2724\nclaude-instant-1            2051\n                            ... \nfalcon-180b-chat             141\nopenchat-3.5-0106            136\nqwen1.5-7b-chat              102\nqwen1.5-4b-chat              100\nmistral-7b-instruct-v0.2      46\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# model_a_won = (train[train['winner_model_a']==1])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:04.670985Z","iopub.execute_input":"2024-05-07T16:59:04.671396Z","iopub.status.idle":"2024-05-07T16:59:04.676889Z","shell.execute_reply.started":"2024-05-07T16:59:04.671365Z","shell.execute_reply":"2024-05-07T16:59:04.675614Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# model_a_won.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:08.973550Z","iopub.execute_input":"2024-05-07T16:59:08.973942Z","iopub.status.idle":"2024-05-07T16:59:08.978473Z","shell.execute_reply.started":"2024-05-07T16:59:08.973912Z","shell.execute_reply":"2024-05-07T16:59:08.977384Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# model_a_won['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:10.982384Z","iopub.execute_input":"2024-05-07T16:59:10.982775Z","iopub.status.idle":"2024-05-07T16:59:10.987587Z","shell.execute_reply.started":"2024-05-07T16:59:10.982745Z","shell.execute_reply":"2024-05-07T16:59:10.986286Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# model_b_won = (train[train['winner_model_b']==1])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:18.366895Z","iopub.execute_input":"2024-05-07T16:59:18.367287Z","iopub.status.idle":"2024-05-07T16:59:18.371809Z","shell.execute_reply.started":"2024-05-07T16:59:18.367253Z","shell.execute_reply":"2024-05-07T16:59:18.370847Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# model_b_won","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:22.650040Z","iopub.execute_input":"2024-05-07T16:59:22.650459Z","iopub.status.idle":"2024-05-07T16:59:22.655017Z","shell.execute_reply.started":"2024-05-07T16:59:22.650425Z","shell.execute_reply":"2024-05-07T16:59:22.653871Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# model_b_won['model_b'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:24.786909Z","iopub.execute_input":"2024-05-07T16:59:24.787296Z","iopub.status.idle":"2024-05-07T16:59:24.792378Z","shell.execute_reply.started":"2024-05-07T16:59:24.787265Z","shell.execute_reply":"2024-05-07T16:59:24.791101Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# model_tied = (train[train['winner_tie']==1])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:27.356961Z","iopub.execute_input":"2024-05-07T16:59:27.357394Z","iopub.status.idle":"2024-05-07T16:59:27.364195Z","shell.execute_reply.started":"2024-05-07T16:59:27.357360Z","shell.execute_reply":"2024-05-07T16:59:27.362069Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"The top 4 models that won most often as model a or as model b are:\n- gpt-4-1106-preview\n- gpt-4-0613\n- gpt-3.5-turbo-0613\n- gpt-4-0314","metadata":{}},{"cell_type":"code","source":"# model_a_ = train[['model_a', 'prompt', 'response_a', 'winner_model_a', 'winner_tie']]\n# model_b_ = train[['model_b', 'prompt', 'response_b', 'winner_model_b', 'winner_tie']]","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:32.102523Z","iopub.execute_input":"2024-05-07T16:59:32.102893Z","iopub.status.idle":"2024-05-07T16:59:32.108066Z","shell.execute_reply.started":"2024-05-07T16:59:32.102863Z","shell.execute_reply":"2024-05-07T16:59:32.106779Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# model_a_.rename(columns={\"model_a\": \"model\", \"response_a\":\"response\", \"winner_model_a\": \"winner\"}, inplace=True)\n# model_b_.rename(columns={\"model_b\": \"model\", \"response_b\":\"response\", \"winner_model_b\": \"winner\"}, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:34.071781Z","iopub.execute_input":"2024-05-07T16:59:34.072163Z","iopub.status.idle":"2024-05-07T16:59:34.079154Z","shell.execute_reply.started":"2024-05-07T16:59:34.072133Z","shell.execute_reply":"2024-05-07T16:59:34.077314Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# model_a_['model'] = model_a_['model'].astype(str)\n# model_b_['model'] = model_b_['model'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:38.483084Z","iopub.execute_input":"2024-05-07T16:59:38.483709Z","iopub.status.idle":"2024-05-07T16:59:38.488536Z","shell.execute_reply.started":"2024-05-07T16:59:38.483675Z","shell.execute_reply":"2024-05-07T16:59:38.487353Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# print(model_a_.info(), model_b_.info())","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:46.615623Z","iopub.execute_input":"2024-05-07T16:59:46.616004Z","iopub.status.idle":"2024-05-07T16:59:46.620912Z","shell.execute_reply.started":"2024-05-07T16:59:46.615975Z","shell.execute_reply":"2024-05-07T16:59:46.619764Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# merged_ab = pd.concat([model_a_, model_b_])\n# merged_ab.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:50.574096Z","iopub.execute_input":"2024-05-07T16:59:50.574517Z","iopub.status.idle":"2024-05-07T16:59:50.579295Z","shell.execute_reply.started":"2024-05-07T16:59:50.574483Z","shell.execute_reply":"2024-05-07T16:59:50.578064Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# merged_ab.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:59:52.475885Z","iopub.execute_input":"2024-05-07T16:59:52.476309Z","iopub.status.idle":"2024-05-07T16:59:52.481215Z","shell.execute_reply.started":"2024-05-07T16:59:52.476275Z","shell.execute_reply":"2024-05-07T16:59:52.479860Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train['models'] = train[['model_a', 'model_b']].values.tolist()\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T21:28:42.334066Z","iopub.execute_input":"2024-05-06T21:28:42.334338Z","iopub.status.idle":"2024-05-06T21:28:42.367722Z","shell.execute_reply.started":"2024-05-06T21:28:42.334316Z","shell.execute_reply":"2024-05-06T21:28:42.366295Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie                                   models  \n0               0           0         [gpt-4-1106-preview, gpt-4-0613]  \n1               1           0                  [koala-13b, gpt-4-0613]  \n2               0           1     [gpt-3.5-turbo-0613, mistral-medium]  \n3               0           0  [llama-2-13b-chat, mistral-7b-instruct]  \n4               1           0          [koala-13b, gpt-3.5-turbo-0314]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n      <th>models</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[gpt-4-1106-preview, gpt-4-0613]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[koala-13b, gpt-4-0613]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[gpt-3.5-turbo-0613, mistral-medium]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[llama-2-13b-chat, mistral-7b-instruct]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[koala-13b, gpt-3.5-turbo-0314]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a function to perform cleaning steps at once (Removes numbers and unnecessary characters, makes all letters lowercase, removes stopwords)\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\n\nno_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\n# no_nums = re.compile('[\\d-]')\n\ndef clean_text(text):\n#     text = no_nums.sub('', text)\n    text = no_bad_chars.sub(' ', text)\n    text = text.lower()\n    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n    return text\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:00:08.218575Z","iopub.execute_input":"2024-05-07T17:00:08.218945Z","iopub.status.idle":"2024-05-07T17:00:08.234812Z","shell.execute_reply.started":"2024-05-07T17:00:08.218914Z","shell.execute_reply":"2024-05-07T17:00:08.233523Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"train_cleaned = train.copy()\ntrain['model_a'] = train['model_a'].astype(str)\ntrain['model_b'] = train['model_b'].astype(str)\ntrain['prompt'] = train['prompt'].astype(str)\ntrain['response_a'] = train['response_a'].astype(str)\ntrain['response_b'] = train['response_b'].astype(str)\n\n\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:02:45.747213Z","iopub.execute_input":"2024-05-07T17:02:45.747657Z","iopub.status.idle":"2024-05-07T17:02:45.775468Z","shell.execute_reply.started":"2024-05-07T17:02:45.747624Z","shell.execute_reply":"2024-05-07T17:02:45.774225Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Applying text cleaning function to text columns\n\ntrain_cleaned['model_a'] = (train['model_a']).apply(clean_text)\ntrain_cleaned['model_b'] = (train['model_b']).apply(clean_text)\ntrain_cleaned['prompt'] = (train['prompt']).apply(clean_text)\ntrain_cleaned['response_a'] = (train['response_a']).apply(clean_text)\ntrain_cleaned['response_b'] = (train['response_b']).apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:03:17.116911Z","iopub.execute_input":"2024-05-07T17:03:17.117315Z","iopub.status.idle":"2024-05-07T17:04:35.479077Z","shell.execute_reply.started":"2024-05-07T17:03:17.117281Z","shell.execute_reply":"2024-05-07T17:04:35.478180Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_cleaned.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:06:05.456844Z","iopub.execute_input":"2024-05-07T17:06:05.457255Z","iopub.status.idle":"2024-05-07T17:06:05.472871Z","shell.execute_reply.started":"2024-05-07T17:06:05.457224Z","shell.execute_reply":"2024-05-07T17:06:05.471642Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt 4 1106 preview           gpt 4 0613   \n1   53567           koala 13b           gpt 4 0613   \n2   65089  gpt 3 5 turbo 0613       mistral medium   \n3   96401    llama 2 13b chat  mistral 7b instruct   \n4  198779           koala 13b   gpt 3 5 turbo 0314   \n\n                                              prompt  \\\n0  morally right try certain percentage females m...   \n1  difference marriage license marriage certifica...   \n2       explain function calling would call function   \n3  create test set rare category want build class...   \n4   best way travel tel aviv jerusalem car bus plane   \n\n                                          response_a  \\\n0  question whether morally right aim certain per...   \n1  marriage license legal document allows couple ...   \n2  function calling process invoking executing fu...   \n3  creating test set rare category challenging ma...   \n4  best way travel tel aviv jerusalem depends per...   \n\n                                          response_b  winner_model_a  \\\n0  ai personal beliefs opinions however tell ques...               1   \n1  marriage license marriage certificate two diff...               0   \n2  function calling process invoking function pro...               0   \n3  building classifier rare category creating tes...               1   \n4  best way travel tel aviv jerusalem depends per...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt 4 1106 preview</td>\n      <td>gpt 4 0613</td>\n      <td>morally right try certain percentage females m...</td>\n      <td>question whether morally right aim certain per...</td>\n      <td>ai personal beliefs opinions however tell ques...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala 13b</td>\n      <td>gpt 4 0613</td>\n      <td>difference marriage license marriage certifica...</td>\n      <td>marriage license legal document allows couple ...</td>\n      <td>marriage license marriage certificate two diff...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt 3 5 turbo 0613</td>\n      <td>mistral medium</td>\n      <td>explain function calling would call function</td>\n      <td>function calling process invoking executing fu...</td>\n      <td>function calling process invoking function pro...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama 2 13b chat</td>\n      <td>mistral 7b instruct</td>\n      <td>create test set rare category want build class...</td>\n      <td>creating test set rare category challenging ma...</td>\n      <td>building classifier rare category creating tes...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala 13b</td>\n      <td>gpt 3 5 turbo 0314</td>\n      <td>best way travel tel aviv jerusalem car bus plane</td>\n      <td>best way travel tel aviv jerusalem depends per...</td>\n      <td>best way travel tel aviv jerusalem depends per...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# X = train_cleaned[['model_a', 'model_b', 'prompt', 'response_a', 'response_b']]\n# y = train_cleaned[['winner_model_a', 'winner_model_b', 'winner_tie']]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:47:34.241356Z","iopub.execute_input":"2024-05-07T17:47:34.241754Z","iopub.status.idle":"2024-05-07T17:47:34.261265Z","shell.execute_reply.started":"2024-05-07T17:47:34.241722Z","shell.execute_reply":"2024-05-07T17:47:34.260304Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# X","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:47:34.457834Z","iopub.execute_input":"2024-05-07T17:47:34.458233Z","iopub.status.idle":"2024-05-07T17:47:34.475395Z","shell.execute_reply.started":"2024-05-07T17:47:34.458202Z","shell.execute_reply":"2024-05-07T17:47:34.474190Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"                  model_a              model_b  \\\n0      gpt 4 1106 preview           gpt 4 0613   \n1               koala 13b           gpt 4 0613   \n2      gpt 3 5 turbo 0613       mistral medium   \n3        llama 2 13b chat  mistral 7b instruct   \n4               koala 13b   gpt 3 5 turbo 0314   \n...                   ...                  ...   \n57472          gpt 4 0613             claude 1   \n57473          claude 2 0     llama 2 13b chat   \n57474            claude 1           alpaca 13b   \n57475              palm 2       tulu 2 dpo 70b   \n57476  gemini pro dev api   gpt 4 1106 preview   \n\n                                                  prompt  \\\n0      morally right try certain percentage females m...   \n1      difference marriage license marriage certifica...   \n2           explain function calling would call function   \n3      create test set rare category want build class...   \n4       best way travel tel aviv jerusalem car bus plane   \n...                                                  ...   \n57472  simple mnemonic \\u03c0 \\n\\ wish could enumerat...   \n57473  python implement naive bayes gaussian mixture ...   \n57474  unethical work building weapons deterrents nec...   \n57475  bait contains 0 0025 bromadiolon much adult ra...   \n57476  three kids eat three apples three days many ap...   \n\n                                              response_a  \\\n0      question whether morally right aim certain per...   \n1      marriage license legal document allows couple ...   \n2      function calling process invoking executing fu...   \n3      creating test set rare category challenging ma...   \n4      best way travel tel aviv jerusalem depends per...   \n...                                                  ...   \n57472  sure let's break \\n\\n1 \\ how\\ 3 letters \\n2 \\ ...   \n57473  implementation naive bayes classifier gaussian...   \n57474  working weapons technology raises ethical ques...   \n57475  bromadiolone rodenticide often used bait secon...   \n57476                                          27 apples   \n\n                                              response_b  \n0      ai personal beliefs opinions however tell ques...  \n1      marriage license marriage certificate two diff...  \n2      function calling process invoking function pro...  \n3      building classifier rare category creating tes...  \n4      best way travel tel aviv jerusalem depends per...  \n...                                                  ...  \n57472  mnemonic represents digits \\u03c0 \\n\\nhow 3 le...  \n57473  sure here's implementation naive bayes classif...  \n57474  depends context weapons used defensive purpose...  \n57475  ai language model promote condone use poison h...  \n57476  three kids eat three apples three days kid eat...  \n\n[57477 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gpt 4 1106 preview</td>\n      <td>gpt 4 0613</td>\n      <td>morally right try certain percentage females m...</td>\n      <td>question whether morally right aim certain per...</td>\n      <td>ai personal beliefs opinions however tell ques...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>koala 13b</td>\n      <td>gpt 4 0613</td>\n      <td>difference marriage license marriage certifica...</td>\n      <td>marriage license legal document allows couple ...</td>\n      <td>marriage license marriage certificate two diff...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gpt 3 5 turbo 0613</td>\n      <td>mistral medium</td>\n      <td>explain function calling would call function</td>\n      <td>function calling process invoking executing fu...</td>\n      <td>function calling process invoking function pro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>llama 2 13b chat</td>\n      <td>mistral 7b instruct</td>\n      <td>create test set rare category want build class...</td>\n      <td>creating test set rare category challenging ma...</td>\n      <td>building classifier rare category creating tes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>koala 13b</td>\n      <td>gpt 3 5 turbo 0314</td>\n      <td>best way travel tel aviv jerusalem car bus plane</td>\n      <td>best way travel tel aviv jerusalem depends per...</td>\n      <td>best way travel tel aviv jerusalem depends per...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>gpt 4 0613</td>\n      <td>claude 1</td>\n      <td>simple mnemonic \\u03c0 \\n\\ wish could enumerat...</td>\n      <td>sure let's break \\n\\n1 \\ how\\ 3 letters \\n2 \\ ...</td>\n      <td>mnemonic represents digits \\u03c0 \\n\\nhow 3 le...</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>claude 2 0</td>\n      <td>llama 2 13b chat</td>\n      <td>python implement naive bayes gaussian mixture ...</td>\n      <td>implementation naive bayes classifier gaussian...</td>\n      <td>sure here's implementation naive bayes classif...</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>claude 1</td>\n      <td>alpaca 13b</td>\n      <td>unethical work building weapons deterrents nec...</td>\n      <td>working weapons technology raises ethical ques...</td>\n      <td>depends context weapons used defensive purpose...</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>palm 2</td>\n      <td>tulu 2 dpo 70b</td>\n      <td>bait contains 0 0025 bromadiolon much adult ra...</td>\n      <td>bromadiolone rodenticide often used bait secon...</td>\n      <td>ai language model promote condone use poison h...</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>gemini pro dev api</td>\n      <td>gpt 4 1106 preview</td>\n      <td>three kids eat three apples three days many ap...</td>\n      <td>27 apples</td>\n      <td>three kids eat three apples three days kid eat...</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# y","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:47:34.595619Z","iopub.execute_input":"2024-05-07T17:47:34.596013Z","iopub.status.idle":"2024-05-07T17:47:34.608183Z","shell.execute_reply.started":"2024-05-07T17:47:34.595984Z","shell.execute_reply":"2024-05-07T17:47:34.606894Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"       winner_model_a  winner_model_b  winner_tie\n0                   1               0           0\n1                   0               1           0\n2                   0               0           1\n3                   1               0           0\n4                   0               1           0\n...               ...             ...         ...\n57472               1               0           0\n57473               1               0           0\n57474               1               0           0\n57475               0               1           0\n57476               1               0           0\n\n[57477 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # train_test_splitting the train dataset:\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:47:34.762450Z","iopub.execute_input":"2024-05-07T17:47:34.762866Z","iopub.status.idle":"2024-05-07T17:47:34.799701Z","shell.execute_reply.started":"2024-05-07T17:47:34.762832Z","shell.execute_reply":"2024-05-07T17:47:34.797750Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# df.reset_index(drop=True,inlpace=True)\n# stopwords_list = nltk.corpus.stopwords.words('english')\n# stopwords_list.extend([\"please\",\"apply\",\"resume\",\"following\",\n# \"client\",\"medical\",\"work\",\"opportunity\"])\nfrom sklearn.linear_model import LogisticRegressionCV\n\ncv = CountVectorizer(max_df =.98,min_df =.05,max_features=9000,ngram_range=(1,3),stop_words = stopwords_list)\n# X = df.loc[:,\"job_description\"]\n# y= df[[\"job_type\",\"category\"]]\nlr  = LogisticRegressionCV(\nclass_weight=\"balanced\",    #accounts for class imbalance\nsolver =\"saga\",             #faster convergence\nmulti_class =\"multinomial\", #accounts for multiclass\ncv=5, #accounts for picking the best score out of all the splits\nscoring='log_loss'       #f1 for imbalanced classification\n)\nX = train_cleaned.loc[:,\"response_b\"]\ny= train_cleaned[['winner_model_a', 'winner_model_b', 'winner_tie']]\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=42)\npipe = Pipeline([(\"c_v\",cv),(\"lr\",MultiOutputClassifier(lr))])\npipe.fit(X_train,y_train)\npredictions = pipe.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:01:26.051161Z","iopub.execute_input":"2024-05-07T18:01:26.051596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Baseline Multinomial Naive Bayes model vectorized with CountVectorizer, tokenized with word_tokenize, \n# # no tuned parameters\n# lr  = LogisticRegressionCV(\n# class_weight=\"balanced\",    #accounts for class imbalance\n# solver =\"saga\",             #faster convergence\n# multi_class =\"multinomial\", #accounts for multiclass\n# cv=5, #accounts for picking the best score out of all the splits\n# scoring='f1_weighted'       #f1 for imbalanced classification\n# )\n# baseline_model = Pipeline([('vect', CountVectorizer(max_features=None,\n#                                                     tokenizer=word_tokenize,\n#                                                    stop_words=stopwords_list)),\n#                            ('clf',MultiOutputClassifier(lr))\n#               ])\n# baseline_model.fit(X_train, y_train)\n\n\n# y_pred = baseline_model.predict(X_test)\n\n# print(log_loss(y_pred, y_test))\n# print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T17:54:20.346513Z","iopub.execute_input":"2024-05-07T17:54:20.347187Z","iopub.status.idle":"2024-05-07T17:54:20.660004Z","shell.execute_reply.started":"2024-05-07T17:54:20.347145Z","shell.execute_reply":"2024-05-07T17:54:20.656913Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[73], line 15\u001b[0m\n\u001b[1;32m      3\u001b[0m lr  \u001b[38;5;241m=\u001b[39m LogisticRegressionCV(\n\u001b[1;32m      4\u001b[0m class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,    \u001b[38;5;66;03m#accounts for class imbalance\u001b[39;00m\n\u001b[1;32m      5\u001b[0m solver \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m,             \u001b[38;5;66;03m#faster convergence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m       \u001b[38;5;66;03m#f1 for imbalanced classification\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m baseline_model \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvect\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                                                     tokenizer\u001b[38;5;241m=\u001b[39mword_tokenize,\n\u001b[1;32m     12\u001b[0m                                                    stop_words\u001b[38;5;241m=\u001b[39mstopwords_list)),\n\u001b[1;32m     13\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m,MultiOutputClassifier(lr))\n\u001b[1;32m     14\u001b[0m               ])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mbaseline_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m baseline_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_loss(y_pred, y_test))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1792\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1786\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratios parameter is only used when penalty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got (penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[1;32m   1788\u001b[0m         )\n\u001b[1;32m   1790\u001b[0m     l1_ratios_ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m-> 1792\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1800\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1802\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 43107]"],"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [5, 43107]","output_type":"error"}]},{"cell_type":"markdown","source":"## Modeling","metadata":{}}]}