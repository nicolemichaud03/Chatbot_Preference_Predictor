{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":6058,"sourceType":"modelInstanceVersion","modelInstanceId":4679,"modelId":2819}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Competition Notebook:\"LMSYS - Chatbot Arena Human Preference Predictions\"","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am conducting data exploration, analysis, and modeling in order to generate predictions for which Chatbot model will be preferred for a given prompt.","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Exploration","metadata":{}},{"cell_type":"markdown","source":"First, import necessary packages, and connect to kaggle to import competition dataset:","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T15:37:29.782187Z","iopub.execute_input":"2024-08-04T15:37:29.782856Z","iopub.status.idle":"2024-08-04T15:37:30.135779Z","shell.execute_reply.started":"2024-08-04T15:37:29.782822Z","shell.execute_reply":"2024-08-04T15:37:30.134937Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n/kaggle/input/lmsys-chatbot-arena/train.csv\n/kaggle/input/lmsys-chatbot-arena/test.csv\n/kaggle/input/bert/keras/bert_base_en/2/config.json\n/kaggle/input/bert/keras/bert_base_en/2/tokenizer.json\n/kaggle/input/bert/keras/bert_base_en/2/metadata.json\n/kaggle/input/bert/keras/bert_base_en/2/model.weights.h5\n/kaggle/input/bert/keras/bert_base_en/2/assets/tokenizer/vocabulary.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set(font_scale=2)\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport nltk\nnltk.download('punkt')\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.metrics import log_loss\nfrom keras.models import Model\nfrom nltk.stem import PorterStemmer, SnowballStemmer\n\n\nimport keras\nimport tensorflow as tf\nfrom keras.utils import normalize, to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, TextVectorization, Softmax, BatchNormalization, Masking\nfrom keras.models import Sequential\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.preprocessing import sequence\nimport keras_tuner as kt\n\n# to avoid warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:40:13.435407Z","iopub.execute_input":"2024-08-04T15:40:13.436387Z","iopub.status.idle":"2024-08-04T15:40:13.449521Z","shell.execute_reply.started":"2024-08-04T15:40:13.436350Z","shell.execute_reply":"2024-08-04T15:40:13.448563Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:34.517230Z","iopub.execute_input":"2024-08-04T15:37:34.517763Z","iopub.status.idle":"2024-08-04T15:37:34.521577Z","shell.execute_reply.started":"2024-08-04T15:37:34.517735Z","shell.execute_reply":"2024-08-04T15:37:34.520521Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Loading and exploring the train and test datasets:","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:34.522823Z","iopub.execute_input":"2024-08-04T15:37:34.523481Z","iopub.status.idle":"2024-08-04T15:37:36.299770Z","shell.execute_reply.started":"2024-08-04T15:37:34.523446Z","shell.execute_reply":"2024-08-04T15:37:36.298946Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.302295Z","iopub.execute_input":"2024-08-04T15:37:36.302597Z","iopub.status.idle":"2024-08-04T15:37:36.320274Z","shell.execute_reply.started":"2024-08-04T15:37:36.302572Z","shell.execute_reply":"2024-08-04T15:37:36.319171Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.321375Z","iopub.execute_input":"2024-08-04T15:37:36.321675Z","iopub.status.idle":"2024-08-04T15:37:36.332019Z","shell.execute_reply.started":"2024-08-04T15:37:36.321640Z","shell.execute_reply":"2024-08-04T15:37:36.330940Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.333317Z","iopub.execute_input":"2024-08-04T15:37:36.334378Z","iopub.status.idle":"2024-08-04T15:37:36.379125Z","shell.execute_reply.started":"2024-08-04T15:37:36.334350Z","shell.execute_reply":"2024-08-04T15:37:36.378141Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.380959Z","iopub.execute_input":"2024-08-04T15:37:36.381628Z","iopub.status.idle":"2024-08-04T15:37:36.406862Z","shell.execute_reply.started":"2024-08-04T15:37:36.381593Z","shell.execute_reply":"2024-08-04T15:37:36.405932Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"I'm interested to see what models are winning most often in the datasets:","metadata":{}},{"cell_type":"code","source":"winner_a = train[train['winner_model_a']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.408026Z","iopub.execute_input":"2024-08-04T15:37:36.408329Z","iopub.status.idle":"2024-08-04T15:37:36.417886Z","shell.execute_reply.started":"2024-08-04T15:37:36.408303Z","shell.execute_reply":"2024-08-04T15:37:36.416928Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"winner_b = train[train['winner_model_b']==True]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.419247Z","iopub.execute_input":"2024-08-04T15:37:36.419939Z","iopub.status.idle":"2024-08-04T15:37:36.428908Z","shell.execute_reply.started":"2024-08-04T15:37:36.419888Z","shell.execute_reply":"2024-08-04T15:37:36.428055Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"winner_a['model_a'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.430171Z","iopub.execute_input":"2024-08-04T15:37:36.430533Z","iopub.status.idle":"2024-08-04T15:37:36.442137Z","shell.execute_reply.started":"2024-08-04T15:37:36.430492Z","shell.execute_reply":"2024-08-04T15:37:36.441025Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"model_a\ngpt-4-1106-preview          2019\ngpt-4-0613                  1280\ngpt-3.5-turbo-0613          1213\ngpt-4-0314                  1033\nclaude-2.1                   896\n                            ... \nchatglm2-6b                   35\nqwen1.5-7b-chat               29\nopenchat-3.5-0106             28\nqwen1.5-4b-chat               19\nmistral-7b-instruct-v0.2      15\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"winner_b['model_b'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.443225Z","iopub.execute_input":"2024-08-04T15:37:36.443492Z","iopub.status.idle":"2024-08-04T15:37:36.454560Z","shell.execute_reply.started":"2024-08-04T15:37:36.443469Z","shell.execute_reply":"2024-08-04T15:37:36.453606Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"model_b\ngpt-4-1106-preview          2054\ngpt-4-0613                  1170\ngpt-3.5-turbo-0613          1168\ngpt-4-0314                   960\nclaude-1                     880\n                            ... \nchatglm2-6b                   38\nopenchat-3.5-0106             35\nqwen1.5-7b-chat               22\nqwen1.5-4b-chat               16\nmistral-7b-instruct-v0.2      12\nName: count, Length: 64, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The top 4 models that won most often as model a or as model b are:\n- gpt-4-1106-preview\n- gpt-4-0613\n- gpt-3.5-turbo-0613\n- gpt-4-0314","metadata":{}},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Since the 'prompt', 'response_a', and 'response_b' features are text, they need to be cleaned and pre-processed before they are tokenized and vectorized.","metadata":{}},{"cell_type":"code","source":"# Need to make sure the relevant features are all in string format\n\ntrain['prompt'] = train['prompt'].astype(str)\ntrain['response_a'] = train['response_a'].astype(str)\ntrain['response_b'] = train['response_b'].astype(str)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.455701Z","iopub.execute_input":"2024-08-04T15:37:36.455995Z","iopub.status.idle":"2024-08-04T15:37:36.471391Z","shell.execute_reply.started":"2024-08-04T15:37:36.455972Z","shell.execute_reply":"2024-08-04T15:37:36.470538Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # getting the total vocab length before text cleaning/preprocessing\n# combined_text1 = train['prompt'] + ' ' + train['response_a'] + ' ' + train['response_b']\n# data1 = combined_text1.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.478307Z","iopub.execute_input":"2024-08-04T15:37:36.478594Z","iopub.status.idle":"2024-08-04T15:37:36.482630Z","shell.execute_reply.started":"2024-08-04T15:37:36.478571Z","shell.execute_reply":"2024-08-04T15:37:36.481674Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary1 = set(word for combined_text1 in data1 for word in combined_text1)\n# print(len(total_vocabulary1))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.483573Z","iopub.execute_input":"2024-08-04T15:37:36.483806Z","iopub.status.idle":"2024-08-04T15:37:36.490637Z","shell.execute_reply.started":"2024-08-04T15:37:36.483781Z","shell.execute_reply":"2024-08-04T15:37:36.489654Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary1)))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.491852Z","iopub.execute_input":"2024-08-04T15:37:36.492306Z","iopub.status.idle":"2024-08-04T15:37:36.497761Z","shell.execute_reply.started":"2024-08-04T15:37:36.492269Z","shell.execute_reply":"2024-08-04T15:37:36.496836Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Before cleaning and preprocessing the text features, the dataset contains 942,074 unique words.","metadata":{}},{"cell_type":"code","source":"# Creating a function to perform cleaning steps at once (Removes numbers and unnecessary characters, makes all letters lowercase, removes stopwords)\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\nstemmer = SnowballStemmer('english')\n\nno_bad_chars = re.compile('[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n - ]')\nno_nums = re.compile('[\\d-]')\n\ndef clean_text(text):\n    text = no_nums.sub('', text)\n    text = no_bad_chars.sub(' ', text)\n    text = text.lower()\n    text = stemmer.stem(text)\n    text = ' '.join(word for word in text.split() if word not in stopwords_list)\n\n    return text\n     ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.498877Z","iopub.execute_input":"2024-08-04T15:37:36.499226Z","iopub.status.idle":"2024-08-04T15:37:36.512269Z","shell.execute_reply.started":"2024-08-04T15:37:36.499196Z","shell.execute_reply":"2024-08-04T15:37:36.511398Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"#Applying text cleaning function to text columns\ntrain_cleaned = train.copy()\ntrain_cleaned['prompt'] = (train['prompt']).apply(clean_text)\ntrain_cleaned['response_a'] = (train['response_a']).apply(clean_text)\ntrain_cleaned['response_b'] = (train['response_b']).apply(clean_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:37:36.513350Z","iopub.execute_input":"2024-08-04T15:37:36.513626Z","iopub.status.idle":"2024-08-04T15:39:23.818137Z","shell.execute_reply.started":"2024-08-04T15:37:36.513603Z","shell.execute_reply":"2024-08-04T15:39:23.817106Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# train_cleaned['winner_model_a'] = train['winner_model_a']\n# train_cleaned['winner_model_b'] = train['winner_model_b']\n# train_cleaned['winner_tie'] = train['winner_tie']","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:23.819686Z","iopub.execute_input":"2024-08-04T15:39:23.820017Z","iopub.status.idle":"2024-08-04T15:39:23.823765Z","shell.execute_reply.started":"2024-08-04T15:39:23.819990Z","shell.execute_reply":"2024-08-04T15:39:23.822805Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.prompt.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:23.825148Z","iopub.execute_input":"2024-08-04T15:39:23.825451Z","iopub.status.idle":"2024-08-04T15:39:23.877774Z","shell.execute_reply.started":"2024-08-04T15:39:23.825417Z","shell.execute_reply":"2024-08-04T15:39:23.876709Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"252"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_a.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:23.879066Z","iopub.execute_input":"2024-08-04T15:39:23.879427Z","iopub.status.idle":"2024-08-04T15:39:23.933404Z","shell.execute_reply.started":"2024-08-04T15:39:23.879396Z","shell.execute_reply":"2024-08-04T15:39:23.932343Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"286"},"metadata":{}}]},{"cell_type":"code","source":"len(train_cleaned[train_cleaned.response_b.str.len()==0])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:23.934738Z","iopub.execute_input":"2024-08-04T15:39:23.935783Z","iopub.status.idle":"2024-08-04T15:39:23.982379Z","shell.execute_reply.started":"2024-08-04T15:39:23.935753Z","shell.execute_reply":"2024-08-04T15:39:23.981297Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"270"},"metadata":{}}]},{"cell_type":"code","source":"train_cleaned2 = train_cleaned[(train_cleaned.prompt.astype(str).str.len()>0) & (train_cleaned.response_a.astype(str).str.len()>0)& (train_cleaned.response_b.astype(str).str.len()>0)]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:23.983666Z","iopub.execute_input":"2024-08-04T15:39:23.984027Z","iopub.status.idle":"2024-08-04T15:39:24.109174Z","shell.execute_reply.started":"2024-08-04T15:39:23.984001Z","shell.execute_reply":"2024-08-04T15:39:24.108181Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_cleaned2.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.110576Z","iopub.execute_input":"2024-08-04T15:39:24.110968Z","iopub.status.idle":"2024-08-04T15:39:24.153756Z","shell.execute_reply.started":"2024-08-04T15:39:24.110934Z","shell.execute_reply":"2024-08-04T15:39:24.152766Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 56800 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              56800 non-null  int64 \n 1   model_a         56800 non-null  object\n 2   model_b         56800 non-null  object\n 3   prompt          56800 non-null  object\n 4   response_a      56800 non-null  object\n 5   response_b      56800 non-null  object\n 6   winner_model_a  56800 non-null  int64 \n 7   winner_model_b  56800 non-null  int64 \n 8   winner_tie      56800 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 4.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_cleaned.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.154999Z","iopub.execute_input":"2024-08-04T15:39:24.155307Z","iopub.status.idle":"2024-08-04T15:39:24.182580Z","shell.execute_reply.started":"2024-08-04T15:39:24.155275Z","shell.execute_reply":"2024-08-04T15:39:24.181706Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                 id  winner_model_a  winner_model_b    winner_tie\ncount  5.747700e+04    57477.000000    57477.000000  57477.000000\nmean   2.142564e+09        0.349079        0.341911      0.309011\nstd    1.238327e+09        0.476683        0.474354      0.462090\nmin    3.019200e+04        0.000000        0.000000      0.000000\n25%    1.071821e+09        0.000000        0.000000      0.000000\n50%    2.133658e+09        0.000000        0.000000      0.000000\n75%    3.211645e+09        1.000000        1.000000      1.000000\nmax    4.294947e+09        1.000000        1.000000      1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.747700e+04</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n      <td>57477.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.142564e+09</td>\n      <td>0.349079</td>\n      <td>0.341911</td>\n      <td>0.309011</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.238327e+09</td>\n      <td>0.476683</td>\n      <td>0.474354</td>\n      <td>0.462090</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.019200e+04</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.071821e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.133658e+09</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.211645e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.294947e+09</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # getting the total vocab length for the trainset after cleaning/preprocessing and removing empty strings\n# combined_text2 = train_cleaned2['prompt'] + ' ' + train_cleaned2['response_a'] + ' ' + train_cleaned2['response_b']\n# data2 = combined_text2.map(word_tokenize).values","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.183795Z","iopub.execute_input":"2024-08-04T15:39:24.184128Z","iopub.status.idle":"2024-08-04T15:39:24.188302Z","shell.execute_reply.started":"2024-08-04T15:39:24.184102Z","shell.execute_reply":"2024-08-04T15:39:24.187286Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# total_vocabulary2 = set(word for combined_text2 in data2 for word in combined_text2)\n# print(len(total_vocabulary2))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.189429Z","iopub.execute_input":"2024-08-04T15:39:24.189717Z","iopub.status.idle":"2024-08-04T15:39:24.195674Z","shell.execute_reply.started":"2024-08-04T15:39:24.189692Z","shell.execute_reply":"2024-08-04T15:39:24.194725Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# print('There are {} unique words in the dataset.'.format(len(total_vocabulary2)))","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.196994Z","iopub.execute_input":"2024-08-04T15:39:24.197347Z","iopub.status.idle":"2024-08-04T15:39:24.203671Z","shell.execute_reply.started":"2024-08-04T15:39:24.197315Z","shell.execute_reply":"2024-08-04T15:39:24.202803Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"<em>After</em> cleaning and preprocessing the text features, the dataset contains 410,804 unique words. This is a huge improvement.","metadata":{}},{"cell_type":"markdown","source":"Removing any unnecessary features:","metadata":{}},{"cell_type":"code","source":"# The features 'model_a','model_b' are not in the test dataset, so I won't use these for modeling\n# Also, the ID feature won't add anything useful to our model so it's best to remove it so it doesn't confuse by adding extra info\n\ntrain_cleaned2.pop('model_a')\n\ntrain_cleaned2.pop('model_b')\n\ntrain_cleaned2.pop('id')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.204741Z","iopub.execute_input":"2024-08-04T15:39:24.205058Z","iopub.status.idle":"2024-08-04T15:39:24.219943Z","shell.execute_reply.started":"2024-08-04T15:39:24.205023Z","shell.execute_reply":"2024-08-04T15:39:24.218946Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0             30192\n1             53567\n2             65089\n3             96401\n4            198779\n            ...    \n57472    4294656694\n57473    4294692063\n57474    4294710549\n57475    4294899228\n57476    4294947231\nName: id, Length: 56800, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Train-test splitting the data:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_, test_ = train_test_split(train_cleaned2, test_size=0.2, random_state=22)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.221287Z","iopub.execute_input":"2024-08-04T15:39:24.221544Z","iopub.status.idle":"2024-08-04T15:39:24.242024Z","shell.execute_reply.started":"2024-08-04T15:39:24.221522Z","shell.execute_reply":"2024-08-04T15:39:24.241076Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"We need to create a target that includes all three of the outcomes we are trying to predict (winner_model_a, winner_model_b, winner_tie):","metadata":{}},{"cell_type":"code","source":"def target(data):\n    y1 = data.pop('winner_model_a')\n    y1 = np.array(y1)\n    y2 = data.pop('winner_model_b')\n    y2 = np.array(y2)\n    y3 = data.pop('winner_tie')\n    y3 = np.array(y3)\n    return y1, y2, y3\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.243235Z","iopub.execute_input":"2024-08-04T15:39:24.243598Z","iopub.status.idle":"2024-08-04T15:39:24.249523Z","shell.execute_reply.started":"2024-08-04T15:39:24.243567Z","shell.execute_reply":"2024-08-04T15:39:24.248495Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#format the outputs for both train and test sets\ntarget_train = target(train_)\ntarget_test = target(test_)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.250759Z","iopub.execute_input":"2024-08-04T15:39:24.251123Z","iopub.status.idle":"2024-08-04T15:39:24.259537Z","shell.execute_reply.started":"2024-08-04T15:39:24.251092Z","shell.execute_reply":"2024-08-04T15:39:24.258489Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"target_train= np.transpose(target_train)\ntarget_test= np.transpose(target_test)\ntarget_train","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.260958Z","iopub.execute_input":"2024-08-04T15:39:24.261504Z","iopub.status.idle":"2024-08-04T15:39:24.269000Z","shell.execute_reply.started":"2024-08-04T15:39:24.261471Z","shell.execute_reply":"2024-08-04T15:39:24.267818Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([[1, 0, 0],\n       [0, 0, 1],\n       [1, 0, 0],\n       ...,\n       [0, 1, 0],\n       [0, 1, 0],\n       [0, 1, 0]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Each of the input features need to be tokenized and vectorized, so that a model can interpret them:","metadata":{}},{"cell_type":"code","source":"print(train_.prompt.str.len().max())\nprint(train_.response_a.str.len().max())\nprint(train_.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.270236Z","iopub.execute_input":"2024-08-04T15:39:24.270669Z","iopub.status.idle":"2024-08-04T15:39:24.372252Z","shell.execute_reply.started":"2024-08-04T15:39:24.270634Z","shell.execute_reply":"2024-08-04T15:39:24.371182Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"24848\n35411\n34440\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_.prompt.str.len().max())\nprint(test_.response_a.str.len().max())\nprint(test_.response_b.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.373705Z","iopub.execute_input":"2024-08-04T15:39:24.374171Z","iopub.status.idle":"2024-08-04T15:39:24.405954Z","shell.execute_reply.started":"2024-08-04T15:39:24.374138Z","shell.execute_reply":"2024-08-04T15:39:24.404977Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"16941\n22387\n41202\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=410804)\n\n# tokenizer.fit_on_texts(list(train_))\n# tokenized_tr = tokenizer.texts_to_sequences(train_)\n\n# tokenized_te = tokenizer.texts_to_sequences(test_)\n ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.407303Z","iopub.execute_input":"2024-08-04T15:39:24.407653Z","iopub.status.idle":"2024-08-04T15:39:24.415483Z","shell.execute_reply.started":"2024-08-04T15:39:24.407621Z","shell.execute_reply":"2024-08-04T15:39:24.414664Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Next, to make sure all the tokenized sequences are the same length, I'm going to pad them all to the length of the <strong>longest sequence</strong>. Any sequences shorter than that will be truncated to meet the size requirement.","metadata":{}},{"cell_type":"code","source":"# max_seq_len = 35411\n# X_train = sequence.pad_sequences(tokenized_tr, maxlen=max_seq_len)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.416578Z","iopub.execute_input":"2024-08-04T15:39:24.416907Z","iopub.status.idle":"2024-08-04T15:39:24.423618Z","shell.execute_reply.started":"2024-08-04T15:39:24.416861Z","shell.execute_reply":"2024-08-04T15:39:24.422771Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# np.shape(target_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.426522Z","iopub.execute_input":"2024-08-04T15:39:24.426855Z","iopub.status.idle":"2024-08-04T15:39:24.431009Z","shell.execute_reply.started":"2024-08-04T15:39:24.426823Z","shell.execute_reply":"2024-08-04T15:39:24.430169Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# max_seq_len = 35411\n# X_test = sequence.pad_sequences(tokenized_te, maxlen=max_seq_len)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.432011Z","iopub.execute_input":"2024-08-04T15:39:24.432335Z","iopub.status.idle":"2024-08-04T15:39:24.438936Z","shell.execute_reply.started":"2024-08-04T15:39:24.432304Z","shell.execute_reply":"2024-08-04T15:39:24.438086Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# X_train = np.transpose(X_train)\n# X_test = np.transpose(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.440270Z","iopub.execute_input":"2024-08-04T15:39:24.440737Z","iopub.status.idle":"2024-08-04T15:39:24.446207Z","shell.execute_reply.started":"2024-08-04T15:39:24.440706Z","shell.execute_reply":"2024-08-04T15:39:24.445389Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"vocab_size = 410804\nmax_seq_len = 35411\n\ntokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<OOV>\", num_words=vocab_size)\ntokenizer.fit_on_texts(train_)\n\nsequences_train = tokenizer.texts_to_sequences(train_)\nsequences_test = tokenizer.texts_to_sequences(test_)\n\npadded_train = pad_sequences(sequences_train, maxlen=max_seq_len, padding='post',truncating='post')\npadded_test = pad_sequences(sequences_test, maxlen=max_seq_len, padding='post', truncating='post')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.452516Z","iopub.execute_input":"2024-08-04T15:39:24.452823Z","iopub.status.idle":"2024-08-04T15:39:24.459228Z","shell.execute_reply.started":"2024-08-04T15:39:24.452802Z","shell.execute_reply":"2024-08-04T15:39:24.458304Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# demonstrate data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n# load data\ndata1 = padded_train\ndata2 = padded_test\n# create scaler\nscaler = MinMaxScaler()\n# fit and transform in one step\nnormalized_train = scaler.fit_transform(data1)\nnormalized_test = scaler.fit_transform(data2)\n\n# inverse transform\ninverse_train = scaler.inverse_transform(normalized_train)\ninverse_test = scaler.inverse_transform(normalized_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.460265Z","iopub.execute_input":"2024-08-04T15:39:24.460550Z","iopub.status.idle":"2024-08-04T15:39:24.475313Z","shell.execute_reply.started":"2024-08-04T15:39:24.460512Z","shell.execute_reply":"2024-08-04T15:39:24.474630Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# # load data\n# data1 = X_train\n# data2 = X_test\n# # create scaler\n# scaler = StandardScaler()\n# # fit and transform in one step\n# standardized_train = scaler.fit_transform(data1)\n# standardized_test = scaler.fit_transform(data2)\n# # inverse transform\n# inverse_train = scaler.inverse_transform(standardized_train)\n# inverse_test = scaler.inverse_transform(standardized_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.477558Z","iopub.execute_input":"2024-08-04T15:39:24.478139Z","iopub.status.idle":"2024-08-04T15:39:24.482067Z","shell.execute_reply.started":"2024-08-04T15:39:24.478115Z","shell.execute_reply":"2024-08-04T15:39:24.481075Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# padded_train = np.transpose(padded_train)\n# padded_test = np.transpose(padded_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.483141Z","iopub.execute_input":"2024-08-04T15:39:24.483437Z","iopub.status.idle":"2024-08-04T15:39:24.489176Z","shell.execute_reply.started":"2024-08-04T15:39:24.483414Z","shell.execute_reply":"2024-08-04T15:39:24.488311Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"inverse_train = np.transpose(inverse_train)\ninverse_test = np.transpose(inverse_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.490360Z","iopub.execute_input":"2024-08-04T15:39:24.490793Z","iopub.status.idle":"2024-08-04T15:39:24.497144Z","shell.execute_reply.started":"2024-08-04T15:39:24.490761Z","shell.execute_reply":"2024-08-04T15:39:24.496321Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                      \n                                  patience=5,\n                                  verbose=1,\n                                  mode=\"min\",\n                                  restore_best_weights=True),\n ]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:39:24.498327Z","iopub.execute_input":"2024-08-04T15:39:24.498622Z","iopub.status.idle":"2024-08-04T15:39:24.505468Z","shell.execute_reply.started":"2024-08-04T15:39:24.498599Z","shell.execute_reply":"2024-08-04T15:39:24.504668Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#sequential model\n\n\ndef get_model():\n    model = Sequential()\n    model.add(Input(shape=(3,)))\n\n    model.add(\n        Embedding(input_dim=410805,\n                  output_dim=150,\n                 mask_zero=True))\n    model.add(Masking(mask_value=0.))\n#     model.add(layers.Flatten())\n    \n    # emb2 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input2 = emb2(input_)\n\n# emb3 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input3 = emb3(input_)\n\n# embs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n\n    model.add(BatchNormalization())\n    model.add(Dropout(0.8))\n    model.add(LSTM(512,return_sequences=True))\n    model.add(LSTM(256))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(128,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(64,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.8))\n    model.add(Dense(32,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.8))\n#     model.add(layers.Flatten())\n    \n    model.add(Dense(3,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:40:52.612955Z","iopub.execute_input":"2024-08-04T15:40:52.613600Z","iopub.status.idle":"2024-08-04T15:40:52.622629Z","shell.execute_reply.started":"2024-08-04T15:40:52.613569Z","shell.execute_reply":"2024-08-04T15:40:52.621715Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model_seq = get_model()\nmodel_seq.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:40:53.204035Z","iopub.execute_input":"2024-08-04T15:40:53.205125Z","iopub.status.idle":"2024-08-04T15:40:53.753792Z","shell.execute_reply.started":"2024-08-04T15:40:53.205084Z","shell.execute_reply":"2024-08-04T15:40:53.752923Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │    \u001b[38;5;34m61,620,750\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │           \u001b[38;5;34m600\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m1,357,824\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">61,620,750</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,357,824</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,811,881\u001b[0m (243.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,811,881</span> (243.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,810,621\u001b[0m (243.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,810,621</span> (243.42 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,260\u001b[0m (4.92 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260</span> (4.92 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model_seq.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=[keras.metrics.CategoricalAccuracy])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:43:10.852874Z","iopub.execute_input":"2024-08-04T15:43:10.853262Z","iopub.status.idle":"2024-08-04T15:43:10.863983Z","shell.execute_reply.started":"2024-08-04T15:43:10.853231Z","shell.execute_reply":"2024-08-04T15:43:10.862884Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model_seq.fit(\n    inverse_train,\n    target_train,\n    validation_split = 0.2,\n    callbacks=callbacks,\n    batch_size=64,\n    shuffle=True,\n    epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:43:11.837507Z","iopub.execute_input":"2024-08-04T15:43:11.838399Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - categorical_accuracy: 0.3521 - loss: 1.0983 - val_categorical_accuracy: 0.3431 - val_loss: 1.0977\nEpoch 2/15\n\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - categorical_accuracy: 0.3407 - loss: 1.0980 - val_categorical_accuracy: 0.3431 - val_loss: 1.0975\nEpoch 3/15\n\u001b[1m311/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - categorical_accuracy: 0.3485 - loss: 1.0974","output_type":"stream"}]},{"cell_type":"code","source":"# keras.utils.plot_model(model_seq, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:31:06.638870Z","iopub.execute_input":"2024-08-04T15:31:06.639734Z","iopub.status.idle":"2024-08-04T15:31:06.643662Z","shell.execute_reply.started":"2024-08-04T15:31:06.639702Z","shell.execute_reply":"2024-08-04T15:31:06.642708Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"preds_seq = model_seq.predict(inverse_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:42:52.118664Z","iopub.execute_input":"2024-08-04T15:42:52.119457Z","iopub.status.idle":"2024-08-04T15:42:56.090553Z","shell.execute_reply.started":"2024-08-04T15:42:52.119421Z","shell.execute_reply":"2024-08-04T15:42:56.089711Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"preds_seq[:10]","metadata":{"execution":{"iopub.status.busy":"2024-08-04T15:42:57.255768Z","iopub.execute_input":"2024-08-04T15:42:57.256484Z","iopub.status.idle":"2024-08-04T15:42:57.263245Z","shell.execute_reply.started":"2024-08-04T15:42:57.256448Z","shell.execute_reply":"2024-08-04T15:42:57.262285Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"array([[0.36094555, 0.56444126, 0.07461315],\n       [0.36710453, 0.3734842 , 0.25941128],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624],\n       [0.3507377 , 0.34372607, 0.30553624]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# #functional model - deepest\n# input_ = Input(shape=(3,))\n\n# # Embed each word in the text features into a ???-dimensional vector\n\n# embedding_size = 100\n\n# emb1 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input1 = emb1(input_)\n\n# emb2 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input2 = emb2(input_)\n\n# emb3 = layers.Embedding(input_dim = 2000, output_dim = embedding_size,  mask_zero=True)\n# emb_input3 = emb3(input_)\n\n# embs = layers.Concatenate(axis=-1)([emb_input1, emb_input2, emb_input3])\n# # embs = keras.layers.GlobalAveragePooling1D()(embs)\n\n# dropout = layers.Dropout(0.8)(emb_input1)\n\n# lstm = layers.LSTM(128, activation='leaky_relu')(dropout)\n\n\n\n# dense1 = layers.Dense(64, activation = 'leaky_relu')(lstm)\n# batch_norm1 = BatchNormalization()(dense1)\n# dropout1 = layers.Dropout(0.8)(batch_norm1)\n# dense2 = layers.Dense(32, activation = 'leaky_relu')(dropout1)\n# batch_norm2 = BatchNormalization()(dense2)\n# dropout2 = layers.Dropout(0.8)(batch_norm2)\n# dense3 = layers.Dense(16, activation = 'leaky_relu')(lstm)\n# batch_norm3 = BatchNormalization()(dense3)\n# dropout3 = layers.Dropout(0.8)(batch_norm3)\n\n# out = layers.Dense(3, activation = 'softmax')(dropout3)\n\n\n# # Instantiate an end-to-end model predicting both priority and department\n# model_func = keras.Model(input_,out)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_func.compile(\n#     loss='categorical_crossentropy', \n#     optimizer=keras.optimizers.Adam(learning_rate=0.001), \n#     metrics=[keras.metrics.CategoricalAccuracy])\n# # keras.metrics.CategoricalAccuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_func.fit(\n#     padded_train,\n#     target_train,\n#     validation_split = 0.1,\n# #     callbacks=callbacks,\n#     batch_size=16,\n#     shuffle=True,\n#     epochs=10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# func_preds = model_func.predict(padded_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# func_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Tuning","metadata":{}},{"cell_type":"code","source":"vocab_size = 410804\n\ndef model_builder(hp):\n    input_ = Input(shape=(3,))\n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n    \n    em =  Embedding(input_dim=vocab_size,output_dim=hp_vector_size, mask_zero=True)\n    emb_input = emb(input_)\n    \n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n    dropout = Dropout(hp_dropout_rate)(emb_input)\n    \n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    lstm = LSTM(hp_lstm_units1,return_sequences=True)(dropout)\n    \n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=16, \n                            max_value=512, \n                            step=64)\n    lstm = LSTM(hp_lstm_units2)(dropout)\n    \n    out = Dense(3,activation='softmax')(lstm)\n    \n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    model = keras.Model(input_,out)\n    \n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size = 400000\n\ndef model_builder(hp):\n    model = Sequential()\n    hp_vector_size = hp.Int('vector_size', \n                            min_value=100, \n                            max_value=500, \n                            step=150)\n    model.add(\n        Embedding(input_dim=vocab_size,\n                  output_dim=150\n#                   input_length=max_seq_len\n                 ))\n    hp_dropout_rate = hp.Float('dropout_rate', \n                               min_value=0.6, \n                               max_value=0.9, \n                               step=0.3)\n    model.add(Dropout(hp_dropout_rate))\n    hp_lstm_units1 = hp.Int('lstm_units1', \n                            min_value=32, \n                            max_value=512, \n                            step=64)\n    model.add(LSTM(hp_lstm_units1,return_sequences=True))\n    hp_lstm_units2 = hp.Int('lstm_units2', \n                            min_value=16, \n                            max_value=512, \n                            step=64)\n    model.add(LSTM(hp_lstm_units2))\n    model.add(Dense(3,activation='softmax'))\n    hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[1e-2, 1e-3, 1e-4])\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntuner1 = kt.Hyperband(model_builder,\n                     objective=kt.Objective(\"val_loss\", direction=\"min\"),\n                     max_epochs=5,\n                     factor=2\n                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntuner1.search(X_train, \n             target_train, \n             epochs=1, \n             validation_split=0.2, \n             callbacks=[stop_early]\n             )\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the optimal hyperparameters\nbest_hps=tuner1.get_best_hyperparameters(num_trials=1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\nmodel_best_hp = tuner1.hypermodel.build(best_hps)\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor='val_loss',\n                                  mode='min',\n                                  patience=5,\n                                  verbose=1,\n                                  restore_best_weights=True)  \n]\nhistory = model_best_hp.fit(X_train, \n                            target_train, \n                            epochs=10,\n                            callbacks=callbacks,\n                            validation_split=0.2)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nmodel_best_hp.save('./model_multiclass_tuned.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Restore model\nloaded_model = tf.keras.models.load_model('./model_multiclass_tuned.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run predict with restored model\npredictions = loaded_model.predict(X_test)\n# winner_model_a = predictions[0]\n# winner_model_b = predictions[1]\n# winner_tie = predictions[2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating predictions for the test dataframe:","metadata":{}},{"cell_type":"code","source":"test.head( )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}